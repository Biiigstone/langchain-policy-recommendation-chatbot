{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fda28-6b3c-49fb-adc3-2bf66e541358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ì„ë² ë”© ë¶€í„° í•˜ì\n",
    "\n",
    "# 1. í•„ìš”í•œ í•„ë“œë¥¼ ì¶”ì¶œí•œë‹¤\n",
    "# 2. LLMì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìì—°ì–´ë¡œ ë³€í™˜í•œë‹¤.\n",
    "# 3. ì„ë² ë”©.\n",
    "\n",
    "# metadataëŠ” policy idì™€ policy nameë§Œ ë„£ì. í•„í„°ë§ì€ RDBì—ì„œ í•˜ê³  ìˆìœ¼ë‹ˆê¹Œ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24750459-0f3b-4cb6-8ae5-ad621df41fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./policy_data.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55608a34-2fdd-43f3-9998-390414eaedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_maps_from_excel_final(filepath):\n",
    "    \"\"\"\n",
    "    (ìµœì¢… ë²„ì „)\n",
    "    í•˜ë‚˜ì˜ ì—‘ì…€ íŒŒì¼ ë‚´ì˜ 'ì½”ë“œì •ë³´' ì‹œíŠ¸ì—ì„œ ì½”ë“œ ì •ë³´ë¥¼ ì½ì–´ì™€\n",
    "    ë¶„ë¥˜ë³„ ì½”ë“œ-ì´ë¦„ ë§µ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    'ì½”ë“œë‚´ìš©' ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ë©°, ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    :param filepath: ì—‘ì…€ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ\n",
    "    :return: ì„±ê³µ ì‹œ ì½”ë“œë§µ ë”•ì…”ë„ˆë¦¬, ì‹¤íŒ¨ ì‹œ None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì—‘ì…€ íŒŒì¼ì˜ 'ì½”ë“œì •ë³´' ì‹œíŠ¸ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "        df_codes = pd.read_excel(filepath, sheet_name='ì½”ë“œì •ë³´')\n",
    "        code_maps = {}\n",
    "        \n",
    "        # 'ë¶„ë¥˜' ì»¬ëŸ¼ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.\n",
    "        for name, group in df_codes.groupby('ë¶„ë¥˜'):\n",
    "            # ê° ê·¸ë£¹ì— 'ì½”ë“œ'ì™€ 'ì½”ë“œë‚´ìš©' ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "            if 'ì½”ë“œ' in group.columns and 'ì½”ë“œë‚´ìš©' in group.columns:\n",
    "                # 'ì½”ë“œ' ë˜ëŠ” 'ì½”ë“œë‚´ìš©'ì— ê²°ì¸¡ì¹˜(NaN)ê°€ ìˆëŠ” í–‰ì€ ì œì™¸í•©ë‹ˆë‹¤.\n",
    "                clean_group = group.dropna(subset=['ì½”ë“œ', 'ì½”ë“œë‚´ìš©'])\n",
    "                # ìµœì¢…ì ìœ¼ë¡œ ì½”ë“œ-ì´ë¦„ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "                code_maps[name] = dict(zip(clean_group['ì½”ë“œ'].astype(str), clean_group['ì½”ë“œë‚´ìš©']))\n",
    "            else:\n",
    "                # í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ëŠ” ê·¸ë£¹ì€ ê±´ë„ˆë›°ê³  ì‚¬ìš©ìì—ê²Œ ê²½ê³  ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "                print(f\"âš ï¸  ê²½ê³ : '{name}' ê·¸ë£¹ì— 'ì½”ë“œ' ë˜ëŠ” 'ì½”ë“œë‚´ìš©' ì»¬ëŸ¼ì´ ì—†ì–´ ì²˜ë¦¬ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        print(\"âœ… ì½”ë“œ ì •ë³´ íŒŒì‹± ì™„ë£Œ!\")\n",
    "        return code_maps\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ğŸš¨ ì˜¤ë¥˜: '{filepath}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"ğŸš¨ ì—‘ì…€ íŒŒì¼ ë‚´ì— 'ì½”ë“œì •ë³´' ì‹œíŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {e})\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_robust_document(row, code_maps):\n",
    "    \"\"\"\n",
    "    (ìµœì¢… ë²„ì „)\n",
    "    íŒŒì‹±ëœ ì½”ë“œë§µê³¼ ì›ë³¸ ë°ì´í„° í–‰(row)ì„ ë°”íƒ•ìœ¼ë¡œ,\n",
    "    ê°ì¢… ì˜ˆì™¸(Null, 'ì œí•œì—†ìŒ' ë“±)ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì˜ë¯¸ì— ì§‘ì¤‘í•œ ìì—°ì–´ ì„¤ëª…ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    :param row: ë°ì´í„°í”„ë ˆì„ì˜ í•œ í–‰ (pandas.Series)\n",
    "    :param code_maps: load_maps_from_excel_final í•¨ìˆ˜ë¡œ ìƒì„±ëœ ì½”ë“œë§µ\n",
    "    :return: ìƒì„±ëœ ìì—°ì–´ ì„¤ëª…ë¬¸ (str)\n",
    "    \"\"\"\n",
    "    # ì½”ë“œì— í•´ë‹¹í•˜ëŠ” ì´ë¦„ì„ ì°¾ì•„ì£¼ëŠ” ë‚´ë¶€ í•¨ìˆ˜\n",
    "    def get_code_name(code_type, code):\n",
    "        if pd.notna(code):\n",
    "            # ì½”ë“œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì°¾ìŠµë‹ˆë‹¤.\n",
    "            return code_maps.get(code_type, {}).get(str(code))\n",
    "        return None\n",
    "\n",
    "    parts = []\n",
    "\n",
    "    # 1. ì •ì±… ê¸°ë³¸ ì •ë³´ (ì´ë¦„, ë¶„ì•¼, í‚¤ì›Œë“œ)\n",
    "    parts.append(f\"ì •ì±…ëª…ì€ '{row.get('plcyNm', 'ì •ë³´ì—†ìŒ')}'ì…ë‹ˆë‹¤.\")\n",
    "    if pd.notna(row.get('lclsfNm')) and pd.notna(row.get('mclsfNm')):\n",
    "        parts.append(f\"ì •ì±… ë¶„ì•¼ëŠ” '{row['lclsfNm']} > {row['mclsfNm']}'ì…ë‹ˆë‹¤.\")\n",
    "    if pd.notna(row.get('plcyKywdNm')):\n",
    "        parts.append(f\"ì£¼ìš” í‚¤ì›Œë“œëŠ” '{row['plcyKywdNm'].replace(',', ', ')}'ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "    # 2. ì •ì±… ìƒì„¸ ì„¤ëª… (í•µì‹¬ ë‚´ìš©)\n",
    "    if pd.notna(row.get('plcyExplnCn')): parts.append(f\"ì •ì±… ì„¤ëª…: {row['plcyExplnCn']}\")\n",
    "    if pd.notna(row.get('plcySprtCn')): parts.append(f\"ì§€ì› ë‚´ìš©: {row['plcySprtCn']}\")\n",
    "\n",
    "    # 3. ìê²© ìš”ê±´ (ì§€ì—­/ê¸°ê°„ ì œì™¸)\n",
    "    condition_parts = []\n",
    "    # ì¶”ê°€ ìê²© ì¡°ê±´ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€\n",
    "    if pd.notna(row.get('addAplyQlfcCndCn')):\n",
    "        condition_parts.append(f\"ì¶”ê°€ ì¡°ê±´: {row['addAplyQlfcCndCn']}\")\n",
    "\n",
    "    # 'ì œí•œ ì—†ìŒ' ë“±ì˜ ì˜ë¯¸ë¥¼ ê°–ëŠ” í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸\n",
    "    unrestricted_keywords = ['ê´€ê³„ì—†ìŒ', 'ì œí•œì—†ìŒ', 'í•™ë ¥ë¬´ê´€']\n",
    "    \n",
    "    # ì½”ë“œì— í•´ë‹¹í•˜ëŠ” ì´ë¦„ì„ ì°¾ì•„, 'ì œí•œ ì—†ìŒ'ì´ ì•„ë‹ ê²½ìš°ì—ë§Œ ìê²© ìš”ê±´ì— ì¶”ê°€\n",
    "    mrg_name = get_code_name('mrgSttsCd', row.get('mrgSttsCd'))\n",
    "    job_name = get_code_name('jobCd', row.get('jobCd'))\n",
    "    edu_name = get_code_name('schoolCd', row.get('schoolCd'))\n",
    "\n",
    "    if mrg_name and mrg_name not in unrestricted_keywords: condition_parts.append(f\"í˜¼ì¸ìƒíƒœ: {mrg_name}\")\n",
    "    if job_name and job_name not in unrestricted_keywords: condition_parts.append(f\"ì·¨ì—…ìƒíƒœ: {job_name}\")\n",
    "    if edu_name and edu_name not in unrestricted_keywords: condition_parts.append(f\"í•™ë ¥: {edu_name}\")\n",
    "\n",
    "    if condition_parts:\n",
    "        parts.append(\"ìê²© ìš”ê±´: \" + \" / \".join(condition_parts))\n",
    "\n",
    "    # ëª¨ë“  ì„¤ëª… íŒŒíŠ¸ë¥¼ í•˜ë‚˜ì˜ ê¸´ ë¬¸ìì—´ë¡œ ê²°í•©\n",
    "    return \" \".join(part for part in parts if part and str(part).strip())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- 1. ì‚¬ìš©ì ì„¤ì • ì˜ì—­ ---\n",
    "    # ğŸ‘ˆ ì—¬ê¸°ì— ì‹¤ì œ ì—‘ì…€ íŒŒì¼ì˜ 'ì ˆëŒ€ ê²½ë¡œ'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
    "    EXCEL_FILE_PATH = './code_table.xlsx'\n",
    "    \n",
    "    # ğŸ‘ˆ ì—¬ê¸°ì— ì›ë³¸ ë°ì´í„° CSV íŒŒì¼ì˜ 'ì ˆëŒ€ ê²½ë¡œ'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
    "    RAW_DATA_PATH = './policy_data.csv'\n",
    "\n",
    "    # --- 2. ì½”ë“œë§µ ë¡œë”© ---\n",
    "    code_maps = load_maps_from_excel_final(EXCEL_FILE_PATH)\n",
    "    \n",
    "    if code_maps:\n",
    "        try:\n",
    "            # --- 3. ì›ë³¸ ë°ì´í„° ë¡œë”© ---\n",
    "            df_raw = pd.read_csv(RAW_DATA_PATH)\n",
    "            print(f\"\\nâœ… ì›ë³¸ ë°ì´í„° '{RAW_DATA_PATH}' ë¡œë”© ì„±ê³µ!\")\n",
    "\n",
    "            # --- 4. ìì—°ì–´ ì„¤ëª…ë¬¸ ìƒì„± ---\n",
    "            print(\"ë¬¸ì„œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "            df_raw['document'] = df_raw.apply(lambda row: create_robust_document(row, code_maps), axis=1)\n",
    "            print(\"âœ… ìµœì¢… ìì—°ì–´ ì„¤ëª…ë¬¸ ìƒì„± ì™„ë£Œ!\")\n",
    "            \n",
    "            # --- 5. ê²°ê³¼ í™•ì¸ ë° ì €ì¥ ---\n",
    "            print(\"\\n--- ìƒì„±ëœ ë¬¸ì„œ ì˜ˆì‹œ (ì²« 5ê°œ) ---\")\n",
    "            for i, doc in enumerate(df_raw['document'].head()):\n",
    "                print(f\"\\n[ì •ì±… {i+1}]\")\n",
    "                print(doc)\n",
    "\n",
    "            # ìƒì„±ëœ ë¬¸ì„œë¥¼ í¬í•¨í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ë³„ë„ì˜ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "            OUTPUT_PATH = './policies_with_documents.csv'\n",
    "            df_raw.to_csv(OUTPUT_PATH, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\n\\nâœ… ëª¨ë“  ë¬¸ì„œê°€ í¬í•¨ëœ ê²°ê³¼ê°€ '{OUTPUT_PATH}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ğŸš¨ ì˜¤ë¥˜: ì›ë³¸ ë°ì´í„° íŒŒì¼ '{RAW_DATA_PATH}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ğŸš¨ ì›ë³¸ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    else:\n",
    "        print(\"\\n\\nğŸš¨ ì½”ë“œë§µ ë¡œë”© ì‹¤íŒ¨ë¡œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c027f9-0d90-4ee5-888b-94aa2101ee02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec2ace-8cc8-4b5b-ad0c-6dbe709fc022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./policy_data.csv')\n",
    "data = data[:10]\n",
    "data.to_csv('./plc_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f421fde-086c-4d2d-8acc-07290d1a107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_maps_from_excel(filepath):\n",
    "    try:\n",
    "        df_codes = pd.read_excel(filepath, sheet_name='ì½”ë“œì •ë³´')\n",
    "        code_maps = {}\n",
    "        for name, group in df_codes.groupby('ë¶„ë¥˜'):\n",
    "            if 'ì½”ë“œ' in group.columns and 'ì½”ë“œë‚´ìš©' in group.columns:\n",
    "                clean_group = group.dropna(subset=['ì½”ë“œ', 'ì½”ë“œë‚´ìš©'])\n",
    "                code_maps[name] = dict(zip(clean_group['ì½”ë“œ'].astype(str), clean_group['ì½”ë“œë‚´ìš©']))\n",
    "        print(\"âœ… Excel íŒŒì¼ì—ì„œ ì½”ë“œ ì •ë³´ íŒŒì‹± ì™„ë£Œ!\")\n",
    "        return code_maps\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_final_document(row, code_maps):\n",
    "    def get_code_name(code_type, code):\n",
    "        if pd.notna(code) and code_maps:\n",
    "            first_code = str(code).split(',')[0].strip()\n",
    "            return code_maps.get(code_type, {}).get(first_code)\n",
    "        return None\n",
    "\n",
    "    policy_name = row.get('plcyNm', 'ì´ë¦„ ì •ë³´ ì—†ìŒ')\n",
    "    region = row.get('rgtrInstCdNm', 'ì „êµ­')\n",
    "    if isinstance(region, str) and ('íŠ¹ë³„ìì¹˜ë„' in region or 'ê´‘ì—­ì‹œ' in region or 'ì‹œ' in region):\n",
    "        region = region.split(' ')[0]\n",
    "\n",
    "    category = f\"{row.get('lclsfNm', '')} > {row.get('mclsfNm', '')}\"\n",
    "    support_content = row.get('plcySprtCn', 'ì§€ì› ë‚´ìš© ì •ë³´ ì—†ìŒ').strip()\n",
    "    \n",
    "    parts = [f\"ì´ ì •ì±…ì€ '{region}'ì—ì„œ ì‹œí–‰í•˜ëŠ” '{policy_name}'ì…ë‹ˆë‹¤.\"]\n",
    "    parts.append(f\"ì •ì±… ë¶„ì•¼ëŠ” '{category}'ì´ë©°, '{support_content}'ì„ ì§€ì›í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    conditions = []\n",
    "    \n",
    "    min_age, max_age = row.get('sprtTrgtMinAge'), row.get('sprtTrgtMaxAge')\n",
    "    if pd.notna(max_age) and max_age > 0:\n",
    "        if pd.notna(min_age) and min_age > 0:\n",
    "            conditions.append(f\"ë§Œ {int(min_age)}ì„¸ì—ì„œ {int(max_age)}ì„¸ ì‚¬ì´ì˜ ì²­ë…„\")\n",
    "        else:\n",
    "            conditions.append(f\"ë§Œ {int(max_age)}ì„¸ ì´í•˜ì˜ ì²­ë…„\")\n",
    "\n",
    "    if pd.notna(row.get('earnEtcCn')) and str(row.get('earnEtcCn')).strip():\n",
    "        conditions.append(f\"ì†Œë“ ì¡°ê±´ì€ '{row['earnEtcCn']}'ì„ ë”°ë¦…ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # --- ìˆ˜ì •ëœ ìê²© ì¡°ê±´ ë¡œì§ ---\n",
    "    unrestricted_keywords = ['ê´€ê³„ì—†ìŒ', 'ì œí•œì—†ìŒ', 'í•™ë ¥ë¬´ê´€', 'ë¬´ê´€']\n",
    "    \n",
    "    # ê²°í˜¼ ìƒíƒœ\n",
    "    mrg_name = get_code_name('mrgSttsCd', row.get('mrgSttsCd'))\n",
    "    if mrg_name and mrg_name not in unrestricted_keywords:\n",
    "        conditions.append(f\"í˜¼ì¸ ìƒíƒœëŠ” '{mrg_name}'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # ì·¨ì—… ìƒíƒœ\n",
    "    job_name = get_code_name('jobCd', row.get('jobCd'))\n",
    "    if job_name:\n",
    "        if job_name in unrestricted_keywords:\n",
    "             conditions.append(\"ì·¨ì—… ìƒíƒœì™€ ê´€ê³„ì—†ì´ ì§€ì› ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "        else:\n",
    "             conditions.append(f\"ì·¨ì—… ìƒíƒœëŠ” '{job_name}'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # í•™ë ¥\n",
    "    edu_name = get_code_name('schoolCd', row.get('schoolCd'))\n",
    "    if edu_name:\n",
    "        if edu_name in unrestricted_keywords:\n",
    "            conditions.append(\"í•™ë ¥ê³¼ ê´€ê³„ì—†ì´ ì§€ì› ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            conditions.append(f\"í•™ë ¥ ì¡°ê±´ì€ '{edu_name}'ì…ë‹ˆë‹¤.\")\n",
    "    # --- ë¡œì§ ìˆ˜ì • ë ---\n",
    "\n",
    "    if pd.notna(row.get('addAplyQlfcCndCn')) and str(row.get('addAplyQlfcCndCn')).strip():\n",
    "        conditions.append(f\"ì¶”ê°€ ìê²©: {row['addAplyQlfcCndCn']}\")\n",
    "\n",
    "    if conditions:\n",
    "        parts.append(\"ì§€ì› ëŒ€ìƒì€ \" + \", \".join(filter(None, conditions)) + \"ì…ë‹ˆë‹¤.\")\n",
    "    \n",
    "    if pd.notna(row.get('plcyAplyMthdCn')) and str(row.get('plcyAplyMthdCn')).strip():\n",
    "        parts.append(f\"ì‹ ì²­ ë°©ë²•ì€ {row['plcyAplyMthdCn']}ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "    return \" \".join(parts)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    POLICY_CSV_PATH = './policy_data.csv'\n",
    "    CODE_EXCEL_PATH = './code_table.xlsx'\n",
    "    OUTPUT_CSV_PATH = './policies_with_documents_final.csv'\n",
    "\n",
    "    try:\n",
    "        df_raw = pd.read_csv(POLICY_CSV_PATH, encoding='utf-8')\n",
    "        print(f\"âœ… ì›ë³¸ CSV ë°ì´í„° '{POLICY_CSV_PATH}' ë¡œë”© ì„±ê³µ!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ğŸš¨ ì˜¤ë¥˜: '{POLICY_CSV_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "\n",
    "    df_raw['sprtTrgtMinAge'] = pd.to_numeric(df_raw['sprtTrgtMinAge'], errors='coerce')\n",
    "    df_raw['sprtTrgtMaxAge'] = pd.to_numeric(df_raw['sprtTrgtMaxAge'], errors='coerce')\n",
    "\n",
    "    code_maps = load_maps_from_excel(CODE_EXCEL_PATH)\n",
    "\n",
    "    if code_maps:\n",
    "        print(\"\\në¬¸ì„œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "        df_raw['document'] = df_raw.apply(lambda row: create_final_document(row, code_maps), axis=1)\n",
    "        print(\"âœ… ìµœì¢… ìì—°ì–´ ì„¤ëª…ë¬¸ ìƒì„± ì™„ë£Œ!\")\n",
    "        df_raw.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nâœ… ëª¨ë“  ë¬¸ì„œê°€ í¬í•¨ëœ ìµœì¢… ê²°ê³¼ê°€ '{OUTPUT_CSV_PATH}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"\\n\\nğŸš¨ ì½”ë“œë§µ ë¡œë”© ì‹¤íŒ¨ë¡œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed94839-b079-40d4-a529-733d3d241117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_spike",
   "language": "python",
   "name": "langchain_spike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
