{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cbc6a-2953-4f01-8326-fbbe5bd2d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d8342-cc67-4377-be39-9eb4d86f1ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcafa7-9084-4b65-9f38-fa757f3f99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-filtering with Chroma DB to avoid GIGO.\n",
    "\n",
    "\n",
    "# 1) 메타데이터는 어떻게 사용되는걸까?\n",
    "# indexing을 하며 계속 의문점이 들었다. 대체 메타데이터를 어떻게 활용하는거지? 머릿속에 든 의문점을 하나씩 적어보자.\n",
    "# 1. 기본적으로 프롬프팅 시 메타데이터를 포함하여 프롬프팅하므로, LLM은 메타데이터를 참고하긴 한다.\n",
    "# 2. 예를 들어, 연도 정보가 중요한 상황일 때, LLM은 충분히 똑똑하므로 현재 시간과 연도 메타데이터를 참고하여 자체적으로 연도가 지난 데이터를 참고하지 않는다.\n",
    "# 3. 즉 r 과정을 통해 가져온 정보가 정확하지 않다면.. 예를 들어 k가 3일 때, 3개 청크의 메타데이터 전부가 2020년의 정보라면, LLM은 지원 가능한 정책이 없다 등으로 답변할 것이다.\n",
    "# 4. 여기서 pre-filtering의 중요성이 대두된다. GIGO를 피하기 위해.\n",
    "\n",
    "# 2) R의 근본적 한계\n",
    "# 1. r은 벡터 DB가 지원하는 단순 유사도 검색을 통해 그 결과를 가져온다.\n",
    "# 2. 즉, 개발자가 필터링 조건을 걸지 않는 이상, 질문과 가장 유사한 벡터를 가져온다. 그것의 메타데이터가 어떻든지 상관하지 않고.\n",
    "# 3. 예를 들어 '30대 남성이 지원 가능한 미술 정책 검색해줘' 라는 질문을 받는다면, DB에 존재하는 모든 문서들.. 00년 부터 25년까지.. 단순 저 질문 자체의 벡터와 가장 유사한 것들을 가져온다는 말이다.\n",
    "# 4. 어쩌면 25년 정책으로 청크들이 구성될 수도 있겠지만, 항상 이를 보장하지는 않는다는 것이 문제이다.\n",
    "# 5. 따라서 이 바보같지만 착한 리트리버를 위해 우리가 필터링을 해 주어야 한다는 것이다(pre-filtering)\n",
    "# 6. 다행히도 벡터DB들은 필터링 쿼리를 제공하므로, 우리는 정규식이나 코드 또는 sLLM 등을 통해 사용자 질문을 기반으로 벡터 쿼리를 잘 생성하기만 하면 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134317d9-001c-4f62-91cd-fba2f7d5af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma DB 세팅하기\n",
    "# https://docs.trychroma.com/docs/querying-collections/metadata-filtering\n",
    "\n",
    "# Chroma는 두 가지 유형의 필터를 제공.\n",
    "# 원하는 조건을 dict 형태로 제공한다.\n",
    "\n",
    "# 메타데이터 필터: Collection.query() 또는 Collection.get()에서 where 절을 사용하여 메타데이터를 기반으로 문서를 필터링\n",
    "# 문서 필터: Collection.query() 또는 Collection.get()에서 where_document를 사용하여 문서 내용을 기반으로 필터링\n",
    "\n",
    "# 필터 연산자(예: $eq, $gt)등을 사용하여 명시적인 필터링이 가능하다.\n",
    "# 이때, 메타데이터의 타입을 구분하여 처리하므로, 숫자 비교 연산자를 올바르게 사용하려면, 메타 데이터의 값도 숫자(int, float) 타입이어야 한다.\n",
    "# 따라서 메타 데이터 필터링을 고려한다면 단순 문자열 코딩은 피해야 한다.\n",
    "# 날짜도 마찬가지.\n",
    "\n",
    "# 5.1 이상의 값\n",
    "# results = collection.query(\n",
    "#     query_texts=[\"검색할 문서입니다\"],\n",
    "#     n_results=2,\n",
    "#     where={\"rating\": {\"$gte\": 5.1}}\n",
    "# )\n",
    "\n",
    "# 크로마 쿼리 작성도 llm이 잘하네!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa437e3-3861-475d-a3e8-1e307aafa93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 따라서 이전의 document from csv 함수를 좀 수정하자\n",
    "# 단순 문자열 필드 -> 숫자 필드로. 날짜 또한 timestamp보단 YYMMDD의 숫자로.\n",
    "\n",
    "import csv\n",
    "from langchain_core.documents import Document\n",
    "from datetime import datetime\n",
    "\n",
    "def create_documents_from_csv(csv_file_path: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    CSV 파일에서 정책 정보를 읽어와 LangChain의 Document 객체 리스트로 변환합니다.\n",
    "    (날짜 처리: YYYYMMDD 정수 변환 방식 적용)\n",
    "    \"\"\"\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    try:\n",
    "        with open(csv_file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            \n",
    "            for row in reader:\n",
    "                # 1. page_content 구성\n",
    "                page_content = f\"\"\"\n",
    "정책명: {row.get('plcyNm', '정보 없음')}\n",
    "정책 설명: {row.get('plcyExplnCn', '정보 없음')}\n",
    "지원 내용: {row.get('plcySprtCn', '정보 없음')}\n",
    "신청 자격: {row.get('addAplyQlfcCndCn', '정보 없음')}\n",
    "\"\"\"\n",
    "                # 2. metadata 기본 구성\n",
    "                metadata = {\n",
    "                    \"policy_id\": row.get('plcyNo'),\n",
    "                    \"policy_name\": row.get('plcyNm'),\n",
    "                    \"main_department\": row.get('sprvsnInstCdNm'),\n",
    "                    \"operating_department\": row.get('operInstCdNm'),\n",
    "                    \"category_large\": row.get('lclsfNm'),\n",
    "                    \"category_medium\": row.get('mclsfNm'),\n",
    "                }\n",
    "\n",
    "                # 3. 숫자 필드 타입 변환\n",
    "                numeric_fields = {\n",
    "                    \"min_age\": row.get('sprtTrgtMinAge'),\n",
    "                    \"max_age\": row.get('sprtTrgtMaxAge'),\n",
    "                }\n",
    "                for key, value in numeric_fields.items():\n",
    "                    if value is not None and value.strip() != '':\n",
    "                        try:\n",
    "                            metadata[key] = int(value)\n",
    "                        except ValueError:\n",
    "                            metadata[key] = value\n",
    "\n",
    "                # 4. 💡 날짜 필드를 YYYYMMDD 정수로 변환\n",
    "                application_period_str = row.get('aplyYmd', '')\n",
    "                if ' ~ ' in application_period_str:\n",
    "                    try:\n",
    "                        start_date_str, end_date_str = application_period_str.split(' ~ ')\n",
    "                        \n",
    "                        # 하이픈(-)을 제거하고 정수로 변환 (예: \"2025-07-21\" -> 20250721)\n",
    "                        metadata['start_date_int'] = int(start_date_str.strip().replace('-', ''))\n",
    "                        metadata['end_date_int'] = int(end_date_str.strip().replace('-', ''))\n",
    "                        \n",
    "                        metadata['application_period_str'] = application_period_str # 원본 문자열도 저장\n",
    "                    except (ValueError, TypeError):\n",
    "                        metadata['application_period_raw'] = application_period_str\n",
    "                else:\n",
    "                     metadata['application_period_raw'] = application_period_str\n",
    "\n",
    "                # 5. 최종 Document 생성\n",
    "                cleaned_metadata = {k: v for k, v in metadata.items() if v is not None and v != ''}\n",
    "                documents.append(Document(page_content=page_content.strip(), metadata=cleaned_metadata))\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: '{csv_file_path}' 파일을 찾을 수 없습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"파일을 읽는 중 오류가 발생했습니다: {e}\")\n",
    "        \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2982bc-57af-4302-bad6-cff5f1c57ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 테스트\n",
    "data = create_documents_from_csv(\"./policy_data.csv\")\n",
    "# data = create_documents_from_csv(\"./test.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cef0c4-2b96-422c-9746-447d81720001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청킹(kss)\n",
    "# 2. kss 청킹\n",
    "\n",
    "import kss\n",
    "\n",
    "\n",
    "def split_docs_with_kss(documents: list[Document], chunk_size: int = 500) -> list[Document]:\n",
    "    \"\"\"\n",
    "    kss를 사용해 문서를 문장 단위로 분할하고,\n",
    "    정해진 chunk_size에 맞게 문장들을 다시 그룹화합니다.\n",
    "    \"\"\"\n",
    "    final_chunks = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # 1. kss로 전체 page_content를 문장 리스트로 분리\n",
    "        sentences = kss.split_sentences(doc.page_content)\n",
    "        \n",
    "        current_chunk_content = \"\"\n",
    "        # 2. 문장들을 순회하며 chunk_size에 가깝게 그룹으로 묶기\n",
    "        for sentence in sentences:\n",
    "            # 현재 문장을 추가하면 chunk_size를 초과하는지 확인\n",
    "            if len(current_chunk_content) + len(sentence) > chunk_size and current_chunk_content:\n",
    "                # 초과한다면, 현재까지의 내용을 하나의 chunk로 만듦\n",
    "                final_chunks.append(\n",
    "                    Document(page_content=current_chunk_content.strip(), metadata=doc.metadata)\n",
    "                )\n",
    "                # 새로운 chunk 시작\n",
    "                current_chunk_content = sentence\n",
    "            else:\n",
    "                # 초과하지 않으면, 현재 chunk에 문장 추가\n",
    "                current_chunk_content += \" \" + sentence\n",
    "\n",
    "        # 마지막에 남아있는 chunk를 리스트에 추가\n",
    "        if current_chunk_content:\n",
    "            final_chunks.append(\n",
    "                Document(page_content=current_chunk_content.strip(), metadata=doc.metadata)\n",
    "            )\n",
    "            \n",
    "    return final_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a870b38a-7a38-42e4-8e55-927cf1312c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = split_docs_with_kss(data)\n",
    "# --- 결과 확인 (실제 실행 시 주석 해제) ---\n",
    "print(f\"원본 Document 수: {len(data)}\")\n",
    "print(f\"분할된 Chunk 수 (kss): {len(split_data)}\")\n",
    "\n",
    "if split_data:\n",
    "    print(\"\\n--- 첫 번째 분할된 Chunk (kss) ---\")\n",
    "    print(split_data[0].page_content)\n",
    "    print(split_data[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c272d41-6a79-4324-8055-9a810db996eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chroma DB 세팅\n",
    "# Chroma DB는 FAISS와 달리, 정말 벡터 DB 라이브러리이다.\n",
    "# 먼저 어떤 임베딩 모델을 사용할지 정하고, 해당 임베딩 모델과 연결된 컬렉션(collection)을 생성해야 한다.\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# # 1. 사용할 임베딩 모델 선택 및 초기화\n",
    "# # 예시: 로컬에서 실행하는 Ollama 모델 사용\n",
    "# embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# # 2. ChromaDB 컬렉션 생성 (from_documents 메서드 사용)\n",
    "# # 이 과정에서 LangChain이 documents의 page_content를 임베딩하고, metadata와 함께 저장합니다.\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=split_data,\n",
    "#     embedding=embedding_model,\n",
    "#     collection_name=\"policy_collection\", # 컬렉션 이름 지정\n",
    "#     persist_directory=\"./chroma_db\" # DB를 저장할 경로\n",
    "# )\n",
    "\n",
    "# print(\"ChromaDB에 Document 저장 완료!\")\n",
    "\n",
    "# # 위 과정을 수행하며 이런 오류를 마주쳤다\n",
    "# BadRequestError: Error code: 400 - {'error': {'message': 'Requested 414416 tokens, max 300000 tokens per request', 'type': 'max_tokens_per_request', 'param': None, 'code': 'max_tokens_per_request'}}\n",
    "# 이는 임베딩 모델의 API 호출 한도를 초과하여 발생하는 오류로, 비어있는 벡터 DB를 생성 후 반복문을 통해 임베딩하는 것으로 해결해야 한다고 한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ea122-0aa6-4fd6-8608-745ca053ca5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c153b4-550e-40a0-911b-cc4e352639b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 처리\n",
    "def add_to_chroma_in_batches(docs: list[Document], batch_size: int = 100):\n",
    "    \"\"\"문서 리스트를 배치로 나누어 ChromaDB에 추가합니다.\"\"\"\n",
    "    \n",
    "    # 전체 문서 리스트를 batch_size만큼 건너뛰며 반복\n",
    "    for i in range(0, len(docs), batch_size):\n",
    "        # 현재 처리할 배치 슬라이싱\n",
    "        batch = docs[i:i + batch_size]\n",
    "        \n",
    "        # 현재 배치만 DB에 추가\n",
    "        vectorstore.add_documents(documents=batch)\n",
    "        \n",
    "        # 진행 상황 출력\n",
    "        print(f\"Batch {i//batch_size + 1}/{(len(docs) - 1)//batch_size + 1} 처리 완료 ({len(batch)}개 문서 추가)\")\n",
    "\n",
    "# 함수 호출로 배치 처리 실행\n",
    "add_to_chroma_in_batches(data, batch_size=200) # 배치 사이즈는 조절 가능\n",
    "\n",
    "print(\"\\n모든 문서의 배치 처리가 완료되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567da1f-9bbc-4956-966d-5313bba98d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터가 잘 저장되었는지 확인\n",
    "# vectorstore.persist()\n",
    "# .persist()가 이전 버전에서 필요했던 이유는 쓰기 작업이 강제로 플러시될 때만 수행되었기 때문입니다. Chroma 0.4.0은 모든 쓰기를 즉시 디스크에 저장하므로 persist가 더 이상 필요하지 않습니다.\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "results = retriever.invoke(\"예술 관련 정책 찾아줘\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bfc524-74b3-4010-891e-aa0fd2001a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건 쿼리 테스트\n",
    "# 연도, 나이 범위로 먼저 필터링 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41febcc-2f0c-4b93-945a-e569506210fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 시나리오 1: 특정 카테고리 필터링 ---\n",
    "# '일자리' 분야의 정책 중에서 '청년 지원'과 관련된 내용 검색\n",
    "print(\"--- [시나리오 1] 카테고리 필터링: '일자리' 분야 ---\")\n",
    "results_category = vectorstore.similarity_search(\n",
    "    query=\"청년 지원\",\n",
    "    k=5,\n",
    "    filter={\"category_large\": \"일자리\"} # category_large 메타데이터가 '일자리'인 문서만 대상\n",
    ")\n",
    "for doc in results_category:\n",
    "    print(f\"  - 정책명: {doc.metadata.get('policy_name', 'N/A')}\")\n",
    "    print(f'내용\\n {doc.page_content}')\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd9572-5335-48f8-a708-04224156da87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 시나리오 2: 나이(숫자 범위) 필터링 ---\n",
    "# 만 19세 이상 39세 미만 청년을 대상으로 하는 정책 검색\n",
    "print(\"\\n--- [시나리오 2] 숫자 범위 필터링: 19세 이상 39세 미만 ---\")\n",
    "results_age = vectorstore.similarity_search(\n",
    "    query=\"자금 지원\",\n",
    "    k=5,\n",
    "    filter={\n",
    "        \"$and\": [\n",
    "            {\"min_age\": {\"$gte\": 19}}, # 'min_age'가 19보다 크거나 같고\n",
    "            {\"max_age\": {\"$lt\": 39}}   # 'max_age'가 39보다 작은 문서\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "for doc in results_age:\n",
    "    print(f\"  - 정책명: {doc.metadata.get('policy_name', 'N/A')}, 연령: {doc.metadata.get('min_age')}~{doc.metadata.get('max_age')}\")\n",
    "    print(f'내용\\n {doc.page_content}')\n",
    "    print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ffd18-20fd-4976-a307-7c4053c3b7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 시나리오 3: 숫자형 날짜(YYMMDD) 필터링\n",
    "today_int = int(datetime.now().strftime(\"%Y%m%d\"))\n",
    "print(f\"오늘 날짜(정수형): {today_int}\\n\")\n",
    "\n",
    "# 3. '현재 신청 가능한' 정책 필터링 검색\n",
    "print(\"--- 현재 신청 가능한 정책 검색 (정수 비교) ---\")\n",
    "results_ongoing = vectorstore.similarity_search(\n",
    "    query=\"주거 지원\",\n",
    "    k=3,\n",
    "    filter={\n",
    "        \"$and\": [\n",
    "            {\"start_date_int\": {\"$lte\": today_int}},\n",
    "            {\"end_date_int\": {\"$gte\": today_int}}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "if not results_ongoing:\n",
    "    print(\"현재 신청 가능한 정책이 없습니다.\")\n",
    "else:\n",
    "    for doc in results_ongoing:\n",
    "        print(f\"  - 정책명: {doc.metadata.get('policy_name', 'N/A')}\")\n",
    "        print(f\"    신청 기간: {doc.metadata.get('application_period_str', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf63a4-4ac4-44be-af05-bc2714b96195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 시나리오 4: 복합 조건 필터링 ($or 사용) ---\n",
    "# '보건복지부' 또는 '여성가족부'에서 주관하며, '주거' 또는 '금융' 분야인 정책 검색\n",
    "print(\"\\n--- [시나리오 4] 복합 조건 필터링: 부처 및 분야 동시 검색 ---\")\n",
    "results_complex = vectorstore.similarity_search(\n",
    "    query=\"저소득층 지원\",\n",
    "    k=5,\n",
    "    filter={\n",
    "        \"$and\": [\n",
    "            {\n",
    "                \"$or\": [\n",
    "                    {\"main_department\": \"보건복지부\"},\n",
    "                    {\"main_department\": \"여성가족부\"}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"$or\": [\n",
    "                    {\"category_large\": \"주거\"},\n",
    "                    {\"category_large\": \"금융\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "for doc in results_complex:\n",
    "    print(f\"  - 정책명: {doc.metadata.get('policy_name', 'N/A')}, 주관부처: {doc.metadata.get('main_department')}, 분야: {doc.metadata.get('category_large')}\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e267286-9baf-4849-ac4d-fff84bf694ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 이렇게 조건 기반 쿼리를 사용할 준비가 되었다면..\n",
    "# 사용자의 질문을 가공하여 쿼리로 변환해야 한다.\n",
    "# 대표적으로 규칙기반(정규식 등)과 LLM을 활용한 방법이 있다.\n",
    "\n",
    "# 규칙기반 시스템의 경우..\n",
    "# 장점 (Pros)\t단점 (Cons)\n",
    "# ✅ 매우 빠름 (LLM API 호출 없음)\t⚠️ 유연하지 않음 (\"내년이면 서른\" 같은 표현 처리 불가)\n",
    "# ✅ 예측 가능하고 일관적임\t⚠️ 규칙이 복잡해지면 유지보수가 어려움 (if/elif 지옥)\n",
    "# ✅ 비용이 들지 않음\t⚠️ 새로운 패턴에 취약함\n",
    "\n",
    "# LLM을 활용할 경우..(자연어 이해-NLU)\n",
    "# 장점 (Pros)\t단점 (Cons)\n",
    "# ✅ 매우 유연하고 강력함 (문맥, 동의어, 복잡한 문장 이해)\t⚠️ 느림 (API 네트워크 지연 시간)\n",
    "# ✅ 유지보수가 쉬움 (프롬프트만 수정하면 됨)\t⚠️ 비용 발생 (API 호출 비용)\n",
    "# ✅ 다양한 사용자 표현에 강함\t⚠️ 결과가 100% 일관적이지 않을 수 있음\n",
    "\n",
    "# 최고의 시스템 및 성능을 원한다면 하이브리드 고려. \n",
    "# 하이브리드는 간단하게나마 우리 시스템에도 적용할 수 있을 것 같음.\n",
    "# 모든 입력에 대해 LLM으로 처리한다면, 많은 비용이 들 것. \n",
    "# 즉, 대놓고 이상한 요청은 규칙 기반으로 충분히 처리 가능하므로.. 이를 기반으로 구축."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80975bdf-022f-45bf-b733-5f2596d2a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계별 필터링 구조(하이브리드)\n",
    "\n",
    "# 1단계) 사전 차단(Guardrail)\n",
    "# 대상 : 인사말, 욕설/비속어, 무의미한 입력, 주제와 무관한 질문 등\n",
    "# 처리 : 미리 준비된 답변을 반환. (예: 안녕하세요! 청년 정책 정보를 찾아드리는 챗 봇입니다!)\n",
    "\n",
    "# 2단계) 간단한 규칙 기반 추출(Fast Path)\n",
    "# 대상 : 키워드나 숫자가 명확히 드러나는 질문(예: 30살 일자리 정책)\n",
    "# 처리 : 규칙 기반 함수 등을 통해 즉시 filter 생성 후 벡터 DB 쿼리.\n",
    "\n",
    "# 3단계) LLM 호출(Fallback)\n",
    "# 대상 : 복잡한 자연어 질문\n",
    "# 처리 : LLM을 호출하여 의도를 파악하고 JSON으로 구조화된 정보 추출. 이를 기반으로 한 filter 생성 후 쿼리\n",
    "# (질의 분석, 화행 분류, 질의 정제, NL2SQL 등의 과정..)\n",
    "\n",
    "# 2단계는 생략하고 1, 3단계만 사용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c4fc9-c647-49e4-8dec-b7f2afc12387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89588d24-cd07-4e2f-a100-1668e757e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473058dd-230a-439f-9ea3-32e9a500eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계 : 사전 차단\n",
    "def is_policy_related_query(query: str) -> bool:\n",
    "    \"\"\"\n",
    "    사용자 질문이 정책 추천 도메인과 관련이 있는지 규칙 기반으로 판단합니다.\n",
    "    (1단계: Guardrail)\n",
    "    \"\"\"\n",
    "    # 긍정 키워드: 이 단어들이 포함되면 관련 질문으로 간주\n",
    "    policy_keywords = [\n",
    "        '정책', '지원', '혜택', '대출', '주거', '일자리', '금융', '교육',\n",
    "        '청년', '신청', '자격', '소득', '보증금', '월세', '취업', '창업'\n",
    "    ]\n",
    "    \n",
    "    # 부정 키워드: 이 단어들이 포함되면 관련 없는 질문으로 간주\n",
    "    unrelated_keywords = [\n",
    "        '날씨', '맛집', '노래', '영화', '드라마', '안녕', '반가워', 'ㅎㅇ',\n",
    "        '사랑', '여행', '게임', '스포츠'\n",
    "    ]\n",
    "\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # 부정 키워드가 하나라도 있으면 즉시 False 반환\n",
    "    if any(keyword in query_lower for keyword in unrelated_keywords):\n",
    "        return False\n",
    "\n",
    "    # 긍정 키워드가 하나라도 있으면 True 반환\n",
    "    if any(keyword in query_lower for keyword in policy_keywords):\n",
    "        return True\n",
    "        \n",
    "    # 위 두 조건에 모두 해당하지 않으면, 관련 없는 것으로 간주 (보수적 접근)\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461e870-be11-48e7-b469-df080d2b9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2단계 : 상세 정보 추출\n",
    "def extract_structured_data_with_llm(query: str) -> dict:\n",
    "    from datetime import datetime\n",
    "    current_date_int = int(datetime.now().strftime('%Y%m%d'))\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    당신은 대한민국 청년 정책에 대한 사용자 질문을 분석하여, Chroma 데이터베이스 검색 필터로 사용할 JSON을 생성하는 AI 어시스턴트입니다.\n",
    "    \n",
    "    # 기본 원칙:\n",
    "    - 사용자가 기간을 명시하지 않으면, 반드시 '현재 신청 가능한' 정책을 찾는 것을 기본값으로 삼아야 합니다.\n",
    "    - 이를 위해, 현재 날짜({current_date_int})를 기준으로 `start_date_int`와 `end_date_int`를 비교하는 필터를 생성해야 합니다.\n",
    "    - **중요**: Chroma는 최상위 레벨에 정확히 하나의 연산자만 허용하므로, 모든 조건을 `$and` 배열로 감싸야 합니다.\n",
    "    \n",
    "    # 지침:\n",
    "    1. 사용자의 질문을 분석하여 필드 정보를 추출하세요.\n",
    "    \n",
    "    2. **필터 구조**: 모든 필터는 반드시 다음과 같은 구조를 따라야 합니다:\n",
    "       {{\"$and\": [조건1, 조건2, ...]}}\n",
    "    \n",
    "    3. **기본 날짜 필터**: 사용자가 기간을 특정하지 않은 모든 경우, 아래 조건들을 **반드시 포함**하세요:\n",
    "       {{\"start_date_int\": {{\"$lte\": {current_date_int}}}}},\n",
    "       {{\"end_date_int\": {{\"$gte\": {current_date_int}}}}}\n",
    "    \n",
    "    4. **나이 필터**: \n",
    "       - 특정 나이 범위(예: \"20대\")를 언급하면, 해당 범위의 정책을 찾기 위해:\n",
    "         {{\"min_age\": {{\"$lte\": 최대연령}}}},  // 정책의 최소 나이가 사용자 최대 나이보다 작거나 같음\n",
    "         {{\"max_age\": {{\"$gte\": 최소연령}}}}   // 정책의 최대 나이가 사용자 최소 나이보다 크거나 같음\n",
    "       - 예: 20대 → min_age <= 29, max_age >= 20\n",
    "    \n",
    "    5. **카테고리 필터**:\n",
    "       - 단순 일치: {{\"category_large\": \"주거\"}}\n",
    "       - 연산자 사용: {{\"category_large\": {{\"$eq\": \"주거\"}}}}\n",
    "    \n",
    "    6. **예외 처리**: 사용자가 '과거', '작년', '모든' 등 기간 제한 없이 검색하길 명시적으로 원하면, 날짜 필터를 포함하지 마세요.\n",
    "    \n",
    "    7. 추가 설명 없이 오직 JSON 객체만 응답해야 합니다.\n",
    "    \n",
    "    # 최종 출력 JSON 예시:\n",
    "    \n",
    "    ## 예시 1: \"20대 주거 정책 찾아줘\" (기본 필터링 적용)\n",
    "    {{\n",
    "        \"$and\": [\n",
    "            {{\"min_age\": {{\"$lte\": 29}}}},\n",
    "            {{\"max_age\": {{\"$gte\": 20}}}},\n",
    "            {{\"category_large\": \"주거\"}},\n",
    "            {{\"start_date_int\": {{\"$lte\": {current_date_int}}}}},\n",
    "            {{\"end_date_int\": {{\"$gte\": {current_date_int}}}}}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    ## 예시 2: \"현재 신청 가능한 청년 정책\" (카테고리 없이)\n",
    "    {{\n",
    "        \"$and\": [\n",
    "            {{\"start_date_int\": {{\"$lte\": {current_date_int}}}}},\n",
    "            {{\"end_date_int\": {{\"$gte\": {current_date_int}}}}}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    ## 예시 3: \"작년에 했던 모든 정책 알려줘\" (기간 제한 없음)\n",
    "    {{}}\n",
    "    \n",
    "    ## 예시 4: \"25살이 받을 수 있는 교육 지원\"\n",
    "    {{\n",
    "        \"$and\": [\n",
    "            {{\"min_age\": {{\"$lte\": 25}}}},\n",
    "            {{\"max_age\": {{\"$gte\": 25}}}},\n",
    "            {{\"category_large\": \"교육\"}},\n",
    "            {{\"start_date_int\": {{\"$lte\": {current_date_int}}}}},\n",
    "            {{\"end_date_int\": {{\"$gte\": {current_date_int}}}}}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # gpt-4o 또는 gpt-4o-mini 추천\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 오류 발생: {e}\")\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e17fd7-de33-4e84-ac5b-0774a1b6fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 지휘자(Orchestrator) 함수\n",
    "def process_query_hybrid(query: str):\n",
    "    \"\"\"하이브리드 방식으로 사용자 질문을 처리하여 최종 ChromaDB 필터를 생성합니다.\"\"\"\n",
    "    print(f\"입력 질문: \\\"{query}\\\"\")\n",
    "    \n",
    "    if not is_policy_related_query(query):\n",
    "        print(\"-> [처리 결과: 규칙 기반 차단]\")\n",
    "        return \"정책과 관련된 질문을 해주세요.\"\n",
    "    \n",
    "    print(\"-> [처리 방식: LLM 호출하여 구조화된 데이터 추출]\")\n",
    "    structured_data = extract_structured_data_with_llm(query)\n",
    "    print(f\"   - LLM 추출 결과 (JSON): {structured_data}\")\n",
    "    return structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207f563-b8df-4cda-8c0d-3aee5ad2f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Case 1: 관련 없는 질문 ---\")\n",
    "final_filter1 = process_query_hybrid(\"오늘 서울 날씨 어때?\")\n",
    "\n",
    "print(\"--- Case 2: 단일 나이 + 카테고리 질문 ---\")\n",
    "final_filter2 = process_query_hybrid(\"서른 살인데, 받을 수 있는 주거 정책이 궁금해\")\n",
    "\n",
    "print(\"--- Case 3: 나이 범위 + 담당부처 질문 ---\")\n",
    "final_filter3 = process_query_hybrid(\"20대를 위한 고용노동부 일자리 정책 좀 찾아줘\")\n",
    "\n",
    "print(\"--- Case 4: 정보는 없지만 관련 있는 질문 ---\")\n",
    "final_filter4 = process_query_hybrid(\"청년들을 위한 지원 정책에는 어떤 종류가 있나요?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d568ee-65e2-496a-aa60-2e2b5f3ae575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 리트리버 기본 세팅\n",
    "# retriever = vectorstore.as_retriever(\n",
    "#     search_type=\"mmr\",\n",
    "#     search_kwargs={'k':5}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65be858-9742-421d-bce3-6d0351c18ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"20대 청년이 받을 수 있는 정책이 궁금해\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d399ac1-8e0b-4dbb-a1d3-208ab11b191d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ff = process_query_hybrid(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200c432-5a34-49c7-9063-19da7f0ef39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved_docs = retriever.invoke(\n",
    "#     user_query,\n",
    "#     search_kwargs={'filter': ff}\n",
    "# )\n",
    "# # 필터링이 참 어렵구나.. 로직의 발상 자체에는 문제가 없어도.. 데이터 자체에 문제가 있는 경우가 많아서 ㅠㅠ\n",
    "\n",
    "# 테스트 필터링\n",
    "# ff = {\n",
    "#     \"$and\": [\n",
    "#         {\"min_age\": {\"$lte\": 20}},  # 주의: 연산자 위치 수정\n",
    "#         {\"max_age\": {\"$gte\": 29}},  # 주의: 연산자 위치 수정\n",
    "#         {\"category_large\": {\"$eq\": \"주거\"}},\n",
    "#         {\"start_date_int\": {\"$lte\": 20250721}},\n",
    "#         {\"end_date_int\": {\"$gte\": 20250721}}\n",
    "#     ]\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bef6c3-7e87-45ab-bbe3-eda637de37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리트리버 대신 벡터 스토어의 유사도 검색 메서드를 직접 호출\n",
    "retrieved_docs = vectorstore.similarity_search(\n",
    "    user_query,\n",
    "    k=20,\n",
    "    filter=ff\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87b79e-094b-4cc2-b844-d9800b913f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(retrieved_docs))\n",
    "for i in retrieved_docs:\n",
    "    print(i.metadata['start_date_int'])\n",
    "    print(i.metadata['end_date_int'])\n",
    "    # print(i)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7599f6-c6f2-4870-98a5-831fade48ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리트리버로도 작동 되나 다시 테스트\n",
    "# 리트리버 기본 세팅\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k':10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53830f50-4ddf-4a0b-82fd-599a5ddcaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\n",
    "    user_query,\n",
    "    search_kwargs={'filter': ff}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce310a-6c22-4335-a350-cc94f5a20fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(retrieved_docs))\n",
    "for i in retrieved_docs:\n",
    "    # print(i.metadata['start_date_int'])\n",
    "    # print(i.metadata['end_date_int'])\n",
    "    print(i)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197488c-732d-491e-92c7-4c5578a1cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 : 적용 안 됨. \n",
    "# 리트리버로 구성 후 동적 필터링을 위해선..\n",
    "# 1. 매 필터마다 동적으로 리트리버를 생성하거나(성능 문제에 대한 생각이 듦..)\n",
    "# 2. configurableRetriever나 RunnableLambda 등을 사용해야 한다.\n",
    "# => LCEL 공부의 필요성 ㅠ\n",
    "\n",
    "# 일단 mvp니까.. 직접 호출하도록 구성하고, 후에 천천히 쌓아올리자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681ff59-24e9-4e35-a9ec-13a28a128d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흠.. 클로드 좀 때려본 결과 다른 필터를 적용한 리트리버를 생성(as_retriever())하는 것은 \n",
    "# 오버헤드가 그렇게 크지 않을 것으로 예상된다고 한다..\n",
    "# 결국 난 랭체인을 활용해야하고, 그러기 위해서는 LCEL을 써야하며 LCEL을 쓰려면 단순 유사도 검색이 아니라\n",
    "# retriever가 필요하므로.. 다른 문제가 발생하지 않는 한, as_retriever()에 동적 필터를 전달하는 방식을 사용하자\n",
    "\n",
    "\n",
    "# 생각해 볼 것 : search_type mmr Vs similarity \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad512fd2-3f59-4e35-9d2d-038bf0a143bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "\n",
    "def get_filtered_retriever(filter_condition):\n",
    "    return vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\":10, \"fetch_k\":30, \"lambda_mult\":0.7, \"filter\": filter_condition}\n",
    "    )\n",
    "\n",
    "r = get_filtered_retriever(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ceb71-256a-43a0-a4b6-e83c9b9086df",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r.invoke(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62045f32-7697-4f3d-8d19-1e93d7992dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(d))\n",
    "for i in d:\n",
    "    print(i.metadata['start_date_int'])\n",
    "    print(i.metadata['end_date_int'])\n",
    "    # print(i)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd348125-560d-40d0-8ef6-2b2f2c7b5f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_spike",
   "language": "python",
   "name": "langchain_spike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
