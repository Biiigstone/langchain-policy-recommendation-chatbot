{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1f53c-3fba-4e92-ac19-4cb4920d4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이걸 잠시 하다보니 다른 생각이 든다..\n",
    "# 필터링을 위한 메타데이터..가 존재해야하나? 벡터 db에서 필터링을 해야하나?\n",
    "# 단순히 연산이 작아보이고 쉬워보여서.. 대충 메타데이터에 넣고, 벡터db에서 필터링 하게 한 게 잘못된 건 아닐까?\n",
    "# 그냥 이러한 필터링 자체는 최대한 rdb 단에서 수행하고, 메타데이터와 벡터db의 사용을 최적화 하는 게 더 좋지 않을까?\n",
    "# => 그렇게 하자. 처음부터 다시하자."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e1426c2-9d61-4677-b74b-c8f0c4ff240a",
   "metadata": {},
   "source": [
    "우리가 RDB로 관리할 필드는.. 특히 필터링과 관련된 필드들..\n",
    "\n",
    "plcyId : PK. \n",
    "\n",
    "A. 사용자 조건 필터\n",
    "- location : 거주지 정보(zipCd 변환 필요)\n",
    "- min_age / max_age : 지원 최소/최대 연령\n",
    "- job_status : 취업 상태(jobCd 변환 필요)\n",
    "- education_level : 학력 요건 (schoolCd 변환 필요)\n",
    "- major : 전공 요건(plcyMajorCd 변환 필요)\n",
    "- income_min / income_max : 소득 최소 최대.\n",
    "\n",
    "B. 정책 내용 기반 필터 \n",
    "- category : 정책 대분류\n",
    "- category_sub : 중분류\n",
    "- keyword : 정책 키워드(예: 대출, 보조금) zipCd와 마찬가지로 정규화 필요\n",
    "\n",
    "C. 기간 및 상태 필터(Time/Status Filters)\n",
    "- biz_start_date / biz_end_date : 사업 시작일 / 종료일\n",
    "- aply_start_date / aply_end_date : 지원 시작일 / 종료일\n",
    "- aplyPrdSeCd : 상시인지 아닌지? 이거 필요한가.. 일단 적어"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98331b32-5944-41b9-9d37-375c8e309de8",
   "metadata": {},
   "source": [
    "필드로 관리할 코드는.. \n",
    "신청기간구분코드(자연어 필드로 충분), 사업기간구분코드(자연어 필드로 충분), 결혼상태코드(자연어 필드로 충분), 소득 조건(자연어 필드로 충분)이고 \n",
    "\n",
    "테이블로 관리할 코드는..\n",
    "정책전공요건코드(o), 정책취업요건코드(o), 정책학력요건코드(o), 정책특화 요건 코드(o), 정책 대분류(o), 정책 중분류(o), 정책 키워드(o).\n",
    "\n",
    "+ 지역 코드(zip) (o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ab570-25e6-4c94-a2a6-aaf051d73811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_code_tables(cursor):\n",
    "    \"\"\"\n",
    "    엑셀 파일의 각 시트를 읽어 코드 테이블에 데이터를 삽입합니다.\n",
    "    \"\"\"\n",
    "    print(\"🚀 코드 테이블 데이터 이관 시작...\")\n",
    "\n",
    "    try:\n",
    "        # 테이블과 시트 이름, 그리고 해당 시트 내의 컬럼명을 매핑합니다.\n",
    "        # 시트 이름은 실제 엑셀 파일의 시트 이름과 정확히 일치해야 합니다.\n",
    "        code_sheets_map = {\n",
    "            'major_codes': ('코드정보', 'plcyMajorCd', '코드', '코드내용'),\n",
    "            'job_status_codes': ('코드정보', 'jobCd', '코드', '코드내용'),\n",
    "            'education_level_codes': ('코드정보', 'schoolCd', '코드', '코드내용'),\n",
    "            'specialization_codes': ('코드정보', 'sBizCd', '코드', '코드내용'),\n",
    "            'category_codes': ('정책대분류', None, '번호', '정책대분류명(lclsfNm)'),\n",
    "            'subcategory_codes': ('정책중분류', None, '번호', '정책중분류명(mclsfNm)'),\n",
    "            'keywords': ('정책키워드', None, None, '정책키워드명(plcyKywdNm)')\n",
    "        }\n",
    "        \n",
    "        for table_name, (sheet_name, filter_col, code_col, name_col) in code_sheets_map.items():\n",
    "            print(f\"  - 테이블 '{table_name}' 작업 중 (시트: '{sheet_name}')...\")\n",
    "            # read_excel을 사용하여 특정 시트를 읽어옵니다.\n",
    "            df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "            \n",
    "            # '코드정보' 시트의 경우, 특정 분류(jobCd 등)로 필터링\n",
    "            if filter_col:\n",
    "                df = df[df['분류'] == filter_col].copy()\n",
    "            \n",
    "            insert_sql = \"\"\n",
    "            # 각 테이블 구조에 맞게 데이터 준비 및 INSERT\n",
    "            if table_name == 'keywords':\n",
    "                insert_sql = f\"INSERT INTO {table_name} (name) VALUES (%s)\"\n",
    "                data_to_insert = [(row[name_col],) for index, row in df.iterrows() if pd.notna(row[name_col])]\n",
    "            else:\n",
    "                insert_sql = f\"INSERT INTO {table_name} (code, name) VALUES (%s, %s)\"\n",
    "                data_to_insert = [(str(row[code_col]), row[name_col]) for index, row in df.iterrows() if pd.notna(row[code_col]) and pd.notna(row[name_col])]\n",
    "            \n",
    "            cursor.executemany(insert_sql, data_to_insert)\n",
    "            print(f\"    ✅ {cursor.rowcount}개 행 삽입 완료.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"🚨 오류: 엑셀 파일('{excel_file_path}')을 찾을 수 없습니다. 파일 이름과 경로를 확인하세요.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 오류: 코드 테이블 이관 중 문제 발생 - {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0d03e-e5eb-44aa-83be-187dee5b4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '1234',\n",
    "    'database': 'toyprj4'\n",
    "}\n",
    "\n",
    "# 엑셀 파일 이름 (사용자님이 변경하신 이름)\n",
    "excel_file_path = './code_table.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a35a3a-7253-44a7-96df-408ea9294e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import \n",
    "connection = None\n",
    "connection = mysql.connector.connect(**db_config)\n",
    "cursor = connection.cursor()\n",
    "print(\"✅ 데이터베이스 연결 성공!\")\n",
    "\n",
    "populate_code_tables(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11da2b4-45e7-4ee0-9ecf-d71f092af519",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "print(\"\\n🎉 모든 작업이 성공적으로 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c0482-327c-4b4f-af51-28e6c70c305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection.rollback()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94014360-9f1f-4a3b-ad49-ad7e1e5a543c",
   "metadata": {},
   "source": [
    "잘 되었는지 확인하기\n",
    "중분류 o 정책특화 o\n",
    "키워드 o 대분류 o\n",
    "\n",
    "나머진 그냥 수동으로 삽입하자. 어차피 많지도 않고..\n",
    "\n",
    "정책 데이터 이관이나 고민할 것\n",
    "(내일 할거) \n",
    "대충 생각하기론.. 여기서 pandas 사용해서 필요한 필드만 우선 추출\n",
    "변환 필요한 필드들 가공\n",
    "csv(또는 json)로 만든 뒤 db에 삽입.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ddff28d-d508-4bcc-b3fd-2c50c20d4d2a",
   "metadata": {},
   "source": [
    "아.. 다시해야한다.. \n",
    "그냥 직접 쓰자 하..\n",
    "\n",
    "일단 코드 테이블은 다 만들었는데.. \n",
    "매핑 테이블이 얼마나 필요한지 다시 생각해보자..\n",
    "몇몇개는 필드로 들어가도 되지만.. 다른 몇몇개는 매핑으로 풀어야 한다..\n",
    "데이터 좀 확인해보자..\n",
    " \n",
    "학력 제한 코드 => 코드,2개 이상인 경우 존재 => 코드 테이블, 매핑 테이블\n",
    "직업 코드 => 코드. 2개 이상인 경우 존재 => 코드 테이블, 매핑 테이블\n",
    "전공 코드 => 코드, 2개 이상인 경우 존재 => 코드 테이블, 매핑 태이블\n",
    "특화 코드 => 코드, 2개 이상인 경우 존재 => 코드 테이블, 매핑 테이블\n",
    "\n",
    "\n",
    "지역 코드 => 상당히 다수에 5자. 3자로 분리 및 코드 테이블, 매핑 테이블\n",
    "\n",
    "정책 대분류/정책 중분류 => 2개 이상 있는 경우 확인 완료. 특히 코드로 된 게 아니고 자연어로 되어있음\n",
    "=> 코드 테이블 삭제, only 매핑 테이블만.. 매핑 테이블에 자연어로 작성.\n",
    "\n",
    "정책 키워드 명 => 마찬가지로 자연어 테이블.. 2개 이상 있는 경우 있으니 매핑 테이블만 사용하자. \n",
    "\n",
    "---\n",
    "구분자는 ',' \n",
    "\n",
    "\n",
    "결혼 상태는.. \n",
    "\n",
    "내일 오면 이관작업 계쏙 하자.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fdb44-084f-4806-8aec-9337fed571fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터가 담긴 CSV 파일 경로\n",
    "csv_file_path = './policy_data.csv' # 실제 파일 이름으로 변경해주세요.\n",
    "\n",
    "try:\n",
    "    # CSV 파일을 DataFrame으로 읽어옵니다.\n",
    "    # 한글 깨짐 방지를 위해 encoding='utf-8'을 사용합니다.\n",
    "    df_raw = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "    \n",
    "    # 데이터 로딩 성공 확인\n",
    "    print(\"✅ 1단계 성공: 데이터 로딩 완료!\")\n",
    "    print(f\"전체 정책 데이터 수: {len(df_raw)}개\")\n",
    "    \n",
    "    # 데이터 구조 확인을 위해 상위 3개 행을 출력합니다.\n",
    "    print(\"\\n--- 원본 데이터 샘플 ---\")\n",
    "    print(df_raw.head(3))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 오류: '{csv_file_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류: 파일을 읽는 중 문제가 발생했습니다. (오류: {e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807a17c-19ab-4aad-846a-77caddc8a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 정제 및 가공\n",
    "# 숫자 형 변환 : 나이, 소득 등 숫자여야 하는 열들의 데이터 타입을 숫자로 확실하게 변환, 숫자로 변환 불가한 경우 NaN 처리\n",
    "# 날짜 형 변환 : yymmdd 형식의 날짜륻릉ㄹ 실제 날짜 형으로 변환하고, 구간 정보의 경우 분리.\n",
    "\n",
    "# --- 2.1. 컬럼 선택 및 이름 변경 (수정) ---\n",
    "column_mapping = {\n",
    "    'plcyNo': 'policy_id',\n",
    "    'plcyNm': 'policy_name',\n",
    "    'plcyExplnCn': 'policy_summary',\n",
    "    'refUrlAddr1': 'source_url',\n",
    "    'sprtTrgtMinAge': 'min_age',\n",
    "    'sprtTrgtMaxAge': 'max_age',\n",
    "    'earnMinAmt': 'income_min',\n",
    "    'earnMaxAmt': 'income_max',\n",
    "    'bizPrdBgngYmd': 'biz_start_date',\n",
    "    'bizPrdEndYmd': 'biz_end_date',\n",
    "    'aplyYmd': 'aply_period',\n",
    "    'mrgSttsCd': 'marriage_status',\n",
    "    'aplyPrdSeCd': 'application_status', \n",
    "    'jobCd': 'job_status_codes',\n",
    "    'schoolCd': 'education_level_codes',\n",
    "    'plcyMajorCd': 'major_codes',\n",
    "    'plcyKywdNm': 'keywords',\n",
    "    'zipCd': 'region_codes',\n",
    "    'lclsfNm': 'category_names',\n",
    "    'mclsfNm': 'subcategory_names',\n",
    "    'rgtrInstCdNm: Operation_Inst'\n",
    "}\n",
    "\n",
    "df_selected = df_raw[list(column_mapping.keys())].copy()\n",
    "df_processed = df_selected.rename(columns=column_mapping)\n",
    "\n",
    "# --- 2.2. 숫자 형식 변환 (변경 없음) ---\n",
    "numeric_cols = ['min_age', 'max_age', 'income_min', 'income_max']\n",
    "for col in numeric_cols:\n",
    "    df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "    df_processed[col] = df_processed[col].replace(0, np.nan)\n",
    "\n",
    "# --- 2.3. 날짜 형식 변환 (변경 없음) ---\n",
    "def to_datetime_safe(date_str):\n",
    "    if pd.isna(date_str) or not isinstance(date_str, str) or not date_str.strip():\n",
    "        return pd.NaT\n",
    "    return pd.to_datetime(date_str, format='%Y%m%d', errors='coerce')\n",
    "\n",
    "def parse_apply_period(period_str):\n",
    "    if pd.isna(period_str) or '~' not in str(period_str):\n",
    "        return pd.NaT, pd.NaT\n",
    "    try:\n",
    "        start_str, end_str = [s.strip() for s in period_str.split('~')]\n",
    "        return to_datetime_safe(start_str), to_datetime_safe(end_str)\n",
    "    except ValueError:\n",
    "        return pd.NaT, pd.NaT\n",
    "\n",
    "df_processed['biz_start_date'] = df_processed['biz_start_date'].apply(to_datetime_safe)\n",
    "df_processed['biz_end_date'] = df_processed['biz_end_date'].apply(to_datetime_safe)\n",
    "df_processed[['aply_start_date', 'aply_end_date']] = df_processed['aply_period'].apply(\n",
    "    lambda x: pd.Series(parse_apply_period(x))\n",
    ")\n",
    "df_processed = df_processed.drop(columns=['aply_period'])\n",
    "\n",
    "print(\"✅ 수정된 2단계 성공: `application_status` 포함하여 정제 완료!\")\n",
    "print(df_processed[['policy_id', 'application_status']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889555a-b37e-432c-90ed-17acd9519fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. policies 테이블용 데이터 프레임 생성\n",
    "\n",
    "# 1. 'policies' 테이블 컬럼 목록 정의 (수정)\n",
    "policy_table_cols = [\n",
    "    'policy_id',\n",
    "    'policy_name',\n",
    "    'policy_summary',\n",
    "    'Operation_Inst',\n",
    "    'source_url',\n",
    "    'min_age',\n",
    "    'max_age',\n",
    "    'income_min',\n",
    "    'income_max',\n",
    "    'biz_start_date',\n",
    "    'biz_end_date',\n",
    "    'aply_start_date',\n",
    "    'aply_end_date',\n",
    "    'marriage_status',\n",
    "    'application_status' \n",
    "]\n",
    "\n",
    "# 2. df_processed에서 해당 컬럼들만 선택하여 최종 policies_df 생성\n",
    "policies_df = df_processed[policy_table_cols].copy()\n",
    "\n",
    "# 3. 결과 확인\n",
    "print(\"\\n✅ 수정된 3단계 성공: `application_status` 포함하여 `policies_df` 생성 완료!\")\n",
    "print(\"\\n--- policies_df 정보 ---\")\n",
    "policies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ad08c-340e-4ce6-96b3-411c3d90e9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 순서 재정렬(DB 스키마 순서와 동일하게)\n",
    "# (선택 사항) DB 스키마 순서와 동일하게 컬럼 순서 재정렬\n",
    "db_schema_order = [\n",
    "    'policy_id', 'min_age', 'max_age', 'income_min', 'income_max',\n",
    "    'biz_start_date', 'biz_end_date', 'aply_start_date', 'aply_end_date',\n",
    "    'application_status', 'marriage_status', 'policy_name', \n",
    "    'policy_summary', 'source_url'\n",
    "]\n",
    "policies_df = policies_df[db_schema_order]\n",
    "\n",
    "# 재정렬된 순서 확인\n",
    "print(policies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db284e4-a981-4635-b415-cdcb3f00ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.info()\n",
    "\n",
    "# df_processed에서 'keywords' 열이 비어있지 않은 행의 개수를 세어봅니다.\n",
    "policies_with_keywords = df_processed['keywords'].notna().sum()\n",
    "\n",
    "print(f\"전체 {len(df_processed)}개 정책 중, 키워드가 할당된 정책의 수: {policies_with_keywords}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56b1a1-039d-4f7d-ae9e-500d271ff2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. 매핑 테이블용 데이터 프레임 생성\n",
    "\n",
    "\n",
    "# 1. 매핑 테이블 생성을 위한 범용 함수 정의\n",
    "def create_mapping_df(df, id_col, value_col, new_value_col_name):\n",
    "    \"\"\"\n",
    "    쉼표로 구분된 값을 가진 컬럼을 분리하여,\n",
    "    정책 ID와 값이 1:1로 매핑되는 '길쭉한' 데이터프레임을 만듭니다.\n",
    "    \n",
    "    :param df: 원본 데이터프레임 (df_processed)\n",
    "    :param id_col: 기준 ID 컬럼명 ('policy_id')\n",
    "    :param value_col: 쉼표로 구분된 값이 있는 컬럼명\n",
    "    :param new_value_col_name: 최종 매핑 테이블의 값 컬럼명\n",
    "    :return: 매핑 테이블용 데이터프레임\n",
    "    \"\"\"\n",
    "    # 1. 필요한 컬럼만 선택하고, 값이 비어있는 행은 제외\n",
    "    temp_df = df[[id_col, value_col]].dropna(subset=[value_col])\n",
    "    \n",
    "    # 2. 쉼표(,)를 기준으로 값을 분리하여 리스트로 만듦\n",
    "    temp_df[value_col] = temp_df[value_col].str.split(',')\n",
    "    \n",
    "    # 3. .explode() 함수로 리스트의 각 항목을 별도의 행으로 펼침\n",
    "    mapping_df = temp_df.explode(value_col)\n",
    "    \n",
    "    # 4. 각 값의 앞뒤 공백 제거\n",
    "    mapping_df[value_col] = mapping_df[value_col].str.strip()\n",
    "    \n",
    "    # 5. 최종 컬럼 이름 변경 (예: value_col -> keyword_name)\n",
    "    mapping_df = mapping_df.rename(columns={value_col: new_value_col_name})\n",
    "    \n",
    "    # 6. 인덱스 초기화\n",
    "    mapping_df = mapping_df.reset_index(drop=True)\n",
    "    \n",
    "    return mapping_df\n",
    "\n",
    "# 2. 'keywords' 컬럼을 사용하여 'policy_keywords' 매핑 테이블 생성\n",
    "policy_keywords_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='keywords', \n",
    "    new_value_col_name='keyword_name' # DB 스키마에 맞게 이름 지정\n",
    ")\n",
    "\n",
    "# 3. 결과 확인\n",
    "print(\"✅ 4-1단계 성공: `policy_keywords_df` 생성 완료!\")\n",
    "print(f\"생성된 키워드 매핑 수: {len(policy_keywords_df)}개\")\n",
    "\n",
    "print(\"\\n--- policy_keywords_df 데이터 샘플 ---\")\n",
    "print(policy_keywords_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafc605-ac15-4317-ac97-d05b41c4fd7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"✅ 4-2단계 시작: 나머지 매핑 테이블들을 생성합니다.\\n\")\n",
    "\n",
    "# 1. 취업 상태(job_status) 매핑 테이블 생성\n",
    "policy_job_status_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='job_status_codes', \n",
    "    new_value_col_name='job_status_code'\n",
    ")\n",
    "print(\"--- `policy_job_status_df` 생성 완료 ---\")\n",
    "print(policy_job_status_df.head())\n",
    "\n",
    "\n",
    "# 2. 학력(education_levels) 매핑 테이블 생성\n",
    "policy_education_levels_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='education_level_codes', \n",
    "    new_value_col_name='education_level_code'\n",
    ")\n",
    "print(\"\\n--- `policy_education_levels_df` 생성 완료 ---\")\n",
    "print(policy_education_levels_df.head())\n",
    "\n",
    "\n",
    "# 3. 전공(majors) 매핑 테이블 생성\n",
    "policy_majors_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='major_codes', \n",
    "    new_value_col_name='major_code'\n",
    ")\n",
    "print(\"\\n--- `policy_majors_df` 생성 완료 ---\")\n",
    "print(policy_majors_df.head())\n",
    "\n",
    "\n",
    "# 4. 지역(regions) 매핑 테이블 생성\n",
    "policy_regions_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='region_codes', \n",
    "    new_value_col_name='region_code'\n",
    ")\n",
    "print(\"\\n--- `policy_regions_df` 생성 완료 ---\")\n",
    "print(policy_regions_df.head())\n",
    "\n",
    "\n",
    "# 5. 카테고리(categories) 매핑 테이블 생성\n",
    "policy_categories_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='category_names', \n",
    "    new_value_col_name='category_name'\n",
    ")\n",
    "print(\"\\n--- `policy_categories_df` 생성 완료 ---\")\n",
    "print(policy_categories_df.head())\n",
    "\n",
    "\n",
    "# 6. 서브카테고리(subcategories) 매핑 테이블 생성\n",
    "policy_subcategories_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='subcategory_names', \n",
    "    new_value_col_name='subcategory_name'\n",
    ")\n",
    "print(\"\\n--- `policy_subcategories_df` 생성 완료 ---\")\n",
    "print(policy_subcategories_df.head())\n",
    "\n",
    "print(\"\\n\\n✅ 4단계 성공: 모든 매핑 테이블용 데이터프레임 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7347c-b812-41fe-829d-c8e42e8a7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타입 디버깅을 위한 확인용 콛,\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 경로\n",
    "CODE_EXCEL_PATH = './code_table.xlsx'\n",
    "\n",
    "try:\n",
    "    # 엑셀 파일의 '코드정보' 시트를 읽어옵니다.\n",
    "    df_codes_debug = pd.read_excel(CODE_EXCEL_PATH, sheet_name='코드정보')\n",
    "\n",
    "    print(\"--- 1. 실제 컬럼 이름 확인 ---\")\n",
    "    print(df_codes_debug.columns.tolist())\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "    # '분류'라는 컬럼이 있는지 확인하고, 있다면 그 안의 고유한 값들을 확인합니다.\n",
    "    if '분류' in df_codes_debug.columns:\n",
    "        print(\"--- 2. '분류' 컬럼의 고유값 확인 ---\")\n",
    "        # ffill()을 먼저 적용해서 비어있는 셀을 채운 후 고유값을 확인합니다.\n",
    "        unique_values = df_codes_debug['분류'].ffill().unique()\n",
    "        print(unique_values)\n",
    "    else:\n",
    "        print(\">>> '분류'라는 이름의 컬럼을 찾을 수 없습니다!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "    \n",
    "    print(\"--- 3. 파일 상위 5줄 내용 확인 ---\")\n",
    "    print(df_codes_debug.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{CODE_EXCEL_PATH}' 파일을 찾을 수 없습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e75706-76a0-4218-a699-36693f625acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04785eeb-ac81-4e61-a26c-db1c077ae7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "\n",
    "# --- 설정 ---\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# 파일 경로\n",
    "POLICY_DATA_PATH = './policy_data.csv'\n",
    "CODE_EXCEL_PATH = './code_table.xlsx'\n",
    "\n",
    "# DB 연결 정보 (!!!반드시 수정!!!)\n",
    "DB_USER = \"root\"\n",
    "DB_PASSWORD = \"1234\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"3306\"\n",
    "DB_NAME = \"toyprj4\"\n",
    "DB_URL = f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "\n",
    "# --- 헬퍼 함수 정의 (변경 없음) ---\n",
    "def to_datetime_safe(date_str):\n",
    "    if pd.isna(date_str) or not isinstance(date_str, str) or not date_str.strip():\n",
    "        return pd.NaT\n",
    "    return pd.to_datetime(date_str, format='%Y%m%d', errors='coerce')\n",
    "\n",
    "def parse_apply_period(period_str):\n",
    "    if pd.isna(period_str) or '~' not in str(period_str):\n",
    "        return pd.NaT, pd.NaT\n",
    "    try:\n",
    "        start_str, end_str = [s.strip() for s in period_str.split('~')]\n",
    "        return to_datetime_safe(start_str), to_datetime_safe(end_str)\n",
    "    except ValueError:\n",
    "        return pd.NaT, pd.NaT\n",
    "\n",
    "def create_mapping_df(df, id_col, value_col, new_value_col_name):\n",
    "    temp_df = df[[id_col, value_col]].dropna(subset=[value_col])\n",
    "    if temp_df.empty:\n",
    "        return pd.DataFrame(columns=[id_col, new_value_col_name])\n",
    "    temp_df[value_col] = temp_df[value_col].astype(str).str.split(',')\n",
    "    mapping_df = temp_df.explode(value_col)\n",
    "    mapping_df[value_col] = mapping_df[value_col].str.strip()\n",
    "    mapping_df = mapping_df.rename(columns={value_col: new_value_col_name})\n",
    "    return mapping_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- 메인 ETL 로직 ---\n",
    "def run_etl():\n",
    "    \"\"\"전체 ETL 프로세스를 실행합니다.\"\"\"\n",
    "    \n",
    "    # --- 1. 추출 (Extract) ---\n",
    "    try:\n",
    "        df_raw = pd.read_csv(POLICY_DATA_PATH, encoding='utf-8')\n",
    "        df_codes = pd.read_excel(CODE_EXCEL_PATH, sheet_name='코드정보', dtype={'코드': str})\n",
    "        logging.info(f\"✅ 1단계 성공: 데이터 및 엑셀 코드 시트 로드 완료.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"❌ 오류: 파일을 찾을 수 없습니다. ({e})\")\n",
    "        return\n",
    "\n",
    "    # --- 2. 변환 (Transform) ---\n",
    "    # 2.1. 코드-자연어 매핑 딕셔너리 생성\n",
    "    code_map = {}\n",
    "    df_codes['분류'] = df_codes['분류'].ffill() \n",
    "    df_codes['코드'] = df_codes['코드'].str.zfill(7)\n",
    "    \n",
    "    code_map['marriage_status'] = df_codes[df_codes['분류'] == 'mrgSttsCd'].set_index('코드')['코드내용'].to_dict()\n",
    "    code_map['application_status'] = df_codes[df_codes['분류'] == 'aplyPrdSeCd'].set_index('코드')['코드내용'].to_dict()\n",
    "    logging.info(\"코드-자연어 매핑 생성 완료.\")\n",
    "    \n",
    "    # 2.2. 기본 정제\n",
    "    column_mapping = {\n",
    "        'plcyNo': 'policy_id', 'plcyNm': 'policy_name', 'plcyExplnCn': 'policy_summary',\n",
    "        'refUrlAddr1': 'source_url', 'sprtTrgtMinAge': 'min_age', 'sprtTrgtMaxAge': 'max_age',\n",
    "        'earnMinAmt': 'income_min', 'earnMaxAmt': 'income_max', 'bizPrdBgngYmd': 'biz_start_date',\n",
    "        'bizPrdEndYmd': 'biz_end_date', 'aplyYmd': 'aply_period', 'mrgSttsCd': 'marriage_status',\n",
    "        'aplyPrdSeCd': 'application_status', 'jobCd': 'job_status_codes', 'schoolCd': 'education_level_codes',\n",
    "        'plcyMajorCd': 'major_codes', 'sbizCd': 'specialization_codes', 'plcyKywdNm': 'keywords',\n",
    "        'zipCd': 'region_codes', 'lclsfNm': 'category_names', 'mclsfNm': 'subcategory_names',\n",
    "        'rgtrInstCdNm': 'operation_inst' # rgtrInstCdNm 컬럼 추가\n",
    "    }\n",
    "    df_processed = df_raw[list(column_mapping.keys())].copy().rename(columns=column_mapping)\n",
    "\n",
    "    # 2.3. 코드를 자연어로 변환\n",
    "    def code_to_natural(series, mapping_dict):\n",
    "        \"\"\"숫자/문자열 코드를 안전하게 자연어로 변환하는 함수\"\"\"\n",
    "        # 1. 비어있는 값(NaN)은 그대로 둠\n",
    "        # 2. pd.to_numeric으로 숫자 변환 시도, 실패 시 NaN\n",
    "        # 3. 정수형으로 변환하여 .0 제거\n",
    "        # 4. 문자열로 변환\n",
    "        # 5. 7자리로 맞춤\n",
    "        # 6. 최종 매핑\n",
    "        return pd.to_numeric(series, errors='coerce').astype('Int64').astype(str).str.zfill(7).map(mapping_dict)\n",
    "\n",
    "    df_processed['marriage_status'] = code_to_natural(df_processed['marriage_status'], code_map['marriage_status'])\n",
    "    df_processed['application_status'] = code_to_natural(df_processed['application_status'], code_map['application_status'])\n",
    "    logging.info(\"결혼상태, 신청상태 코드 -> 자연어 변환 완료.\")\n",
    "\n",
    "    # 2.4. 숫자 및 날짜 변환\n",
    "    numeric_cols = ['min_age', 'max_age', 'income_min', 'income_max']\n",
    "    for col in numeric_cols:\n",
    "        df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce').replace(0, np.nan)\n",
    "\n",
    "    df_processed['biz_start_date'] = df_processed['biz_start_date'].apply(to_datetime_safe)\n",
    "    df_processed['biz_end_date'] = df_processed['biz_end_date'].apply(to_datetime_safe)\n",
    "    df_processed[['aply_start_date', 'aply_end_date']] = df_processed['aply_period'].apply(lambda x: pd.Series(parse_apply_period(x)))\n",
    "    df_processed = df_processed.drop(columns=['aply_period'])\n",
    "    logging.info(\"✅ 2단계 성공: 전체 데이터 정제 및 가공 완료.\")\n",
    "\n",
    "    # --- 3. 변환 (Transform) - `policies` 테이블용 데이터프레임 생성 ---\n",
    "    policy_table_cols = [\n",
    "        'policy_id', 'policy_name', 'policy_summary', 'source_url', 'min_age', 'max_age',\n",
    "        'income_min', 'income_max', 'biz_start_date', 'biz_end_date', 'aply_start_date',\n",
    "        'aply_end_date', 'marriage_status', 'application_status',\n",
    "        'operation_inst' # `policies` 테이블에 추가된 컬럼\n",
    "    ]\n",
    "    policies_df = df_processed[policy_table_cols].copy()\n",
    "    logging.info(\"✅ 3단계 성공: `policies` 테이블용 데이터프레임 생성 완료.\")\n",
    "\n",
    "    # --- 4. 변환 (Transform) - 매핑 테이블용 데이터프레임 생성 ---\n",
    "    policy_keywords_df = create_mapping_df(df_processed, 'policy_id', 'keywords', 'keyword_name')\n",
    "    policy_job_status_df = create_mapping_df(df_processed, 'policy_id', 'job_status_codes', 'job_status_code')\n",
    "    policy_education_levels_df = create_mapping_df(df_processed, 'policy_id', 'education_level_codes', 'education_level_code')\n",
    "    policy_majors_df = create_mapping_df(df_processed, 'policy_id', 'major_codes', 'major_code')\n",
    "    policy_regions_df = create_mapping_df(df_processed, 'policy_id', 'region_codes', 'region_code')\n",
    "    policy_categories_df = create_mapping_df(df_processed, 'policy_id', 'category_names', 'category_name')\n",
    "    policy_subcategories_df = create_mapping_df(df_processed, 'policy_id', 'subcategory_names', 'subcategory_name')\n",
    "    policy_specializations_df = create_mapping_df(df_processed, 'policy_id', 'specialization_codes', 'specialization_code')\n",
    "    logging.info(\"✅ 4단계 성공: 모든 매핑 테이블용 데이터프레임 생성 완료.\")\n",
    "\n",
    "    # --- 5. 적재 (Load) ---\n",
    "    try:\n",
    "        engine = create_engine(DB_URL)\n",
    "        logging.info(f\"데이터베이스 '{DB_NAME}'에 연결되었습니다.\")\n",
    "        \n",
    "        dataframes_to_load = {\n",
    "            'policies': policies_df,\n",
    "            'policy_keywords': policy_keywords_df,\n",
    "            'policy_job_status': policy_job_status_df,\n",
    "            'policy_education_levels': policy_education_levels_df,\n",
    "            'policy_majors': policy_majors_df,\n",
    "            'policy_regions': policy_regions_df,\n",
    "            'policy_categories': policy_categories_df,\n",
    "            'policy_subcategories': policy_subcategories_df,\n",
    "            'policy_specializations': policy_specializations_df\n",
    "        }\n",
    "\n",
    "        for table_name, df in dataframes_to_load.items():\n",
    "            df.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "            logging.info(f\"-> 테이블 '{table_name}'에 {len(df)}개 행 적재 완료.\")\n",
    "        \n",
    "        logging.info(\"🎉 5단계 성공: 모든 데이터 적재 작업이 완료되었습니다!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ 5단계 오류: 데이터베이스 연결 또는 적재 중 오류 발생: {e}\")\n",
    "\n",
    "# --- 스크립트 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4a3d5-600e-4cc1-b721-f1f0653b5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "POLICY_DATA_PATH = './policy_data.csv'\n",
    "CODE_EXCEL_PATH = './code_table.xlsx'\n",
    "\n",
    "try:\n",
    "    # 1. 각 파일을 읽어옵니다.\n",
    "    df_raw_debug = pd.read_csv(POLICY_DATA_PATH, encoding='utf-8')\n",
    "    df_codes_debug = pd.read_excel(CODE_EXCEL_PATH, sheet_name='코드정보', dtype={'코드': str})\n",
    "\n",
    "    # --- marriage_status 매핑 과정만 집중 분석 ---\n",
    "\n",
    "    # 2. 코드 매핑 딕셔너리를 만듭니다.\n",
    "    df_codes_debug['분류'] = df_codes_debug['분류'].ffill()\n",
    "    df_codes_debug['코드'] = df_codes_debug['코드'].str.zfill(7)\n",
    "    \n",
    "    marriage_map = df_codes_debug[df_codes_debug['분류'] == 'mrgSttsCd'].set_index('코드')['코드내용'].to_dict()\n",
    "\n",
    "    print(\"--- 1. 생성된 결혼상태(marriage_status) 매핑 딕셔너리 ---\")\n",
    "    print(marriage_map)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "    # 3. 원본 데이터의 'mrgSttsCd' 값들을 확인합니다.\n",
    "    #    값이 비어있지 않은 샘플 5개를 가져옵니다.\n",
    "    sample_codes = df_raw_debug['mrgSttsCd'].dropna().head(5)\n",
    "    \n",
    "    print(\"--- 2. 원본 데이터의 'mrgSttsCd' 샘플 ---\")\n",
    "    print(sample_codes)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    \n",
    "    # 4. 이 샘플들이 어떻게 변환되는지 확인합니다.\n",
    "    print(\"--- 3. 샘플 코드 변환 과정 및 매핑 결과 ---\")\n",
    "    for code in sample_codes:\n",
    "        # 원본 값을 문자열로 바꾸고 7자리로 만듭니다.\n",
    "        processed_code = str(code).zfill(7)\n",
    "        # 매핑 딕셔너리에서 값을 찾아봅니다.\n",
    "        mapped_value = marriage_map.get(processed_code, \">>> 매핑 실패! <<<\")\n",
    "        \n",
    "        print(f\"원본: {code}  ->  변환 후: '{processed_code}'  ->  매핑 결과: {mapped_value}\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"오류: 파일을 찾을 수 없습니다. ({e})\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_spike",
   "language": "python",
   "name": "langchain_spike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
