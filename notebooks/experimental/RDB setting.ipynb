{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1f53c-3fba-4e92-ac19-4cb4920d4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ê±¸ ì ì‹œ í•˜ë‹¤ë³´ë‹ˆ ë‹¤ë¥¸ ìƒê°ì´ ë“ ë‹¤..\n",
    "# í•„í„°ë§ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„°..ê°€ ì¡´ì¬í•´ì•¼í•˜ë‚˜? ë²¡í„° dbì—ì„œ í•„í„°ë§ì„ í•´ì•¼í•˜ë‚˜?\n",
    "# ë‹¨ìˆœíˆ ì—°ì‚°ì´ ì‘ì•„ë³´ì´ê³  ì‰¬ì›Œë³´ì—¬ì„œ.. ëŒ€ì¶© ë©”íƒ€ë°ì´í„°ì— ë„£ê³ , ë²¡í„°dbì—ì„œ í•„í„°ë§ í•˜ê²Œ í•œ ê²Œ ì˜ëª»ëœ ê±´ ì•„ë‹ê¹Œ?\n",
    "# ê·¸ëƒ¥ ì´ëŸ¬í•œ í•„í„°ë§ ìì²´ëŠ” ìµœëŒ€í•œ rdb ë‹¨ì—ì„œ ìˆ˜í–‰í•˜ê³ , ë©”íƒ€ë°ì´í„°ì™€ ë²¡í„°dbì˜ ì‚¬ìš©ì„ ìµœì í™” í•˜ëŠ” ê²Œ ë” ì¢‹ì§€ ì•Šì„ê¹Œ?\n",
    "# => ê·¸ë ‡ê²Œ í•˜ì. ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ì."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e1426c2-9d61-4677-b74b-c8f0c4ff240a",
   "metadata": {},
   "source": [
    "ìš°ë¦¬ê°€ RDBë¡œ ê´€ë¦¬í•  í•„ë“œëŠ”.. íŠ¹íˆ í•„í„°ë§ê³¼ ê´€ë ¨ëœ í•„ë“œë“¤..\n",
    "\n",
    "plcyId : PK. \n",
    "\n",
    "A. ì‚¬ìš©ì ì¡°ê±´ í•„í„°\n",
    "- location : ê±°ì£¼ì§€ ì •ë³´(zipCd ë³€í™˜ í•„ìš”)\n",
    "- min_age / max_age : ì§€ì› ìµœì†Œ/ìµœëŒ€ ì—°ë ¹\n",
    "- job_status : ì·¨ì—… ìƒíƒœ(jobCd ë³€í™˜ í•„ìš”)\n",
    "- education_level : í•™ë ¥ ìš”ê±´ (schoolCd ë³€í™˜ í•„ìš”)\n",
    "- major : ì „ê³µ ìš”ê±´(plcyMajorCd ë³€í™˜ í•„ìš”)\n",
    "- income_min / income_max : ì†Œë“ ìµœì†Œ ìµœëŒ€.\n",
    "\n",
    "B. ì •ì±… ë‚´ìš© ê¸°ë°˜ í•„í„° \n",
    "- category : ì •ì±… ëŒ€ë¶„ë¥˜\n",
    "- category_sub : ì¤‘ë¶„ë¥˜\n",
    "- keyword : ì •ì±… í‚¤ì›Œë“œ(ì˜ˆ: ëŒ€ì¶œ, ë³´ì¡°ê¸ˆ) zipCdì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì •ê·œí™” í•„ìš”\n",
    "\n",
    "C. ê¸°ê°„ ë° ìƒíƒœ í•„í„°(Time/Status Filters)\n",
    "- biz_start_date / biz_end_date : ì‚¬ì—… ì‹œì‘ì¼ / ì¢…ë£Œì¼\n",
    "- aply_start_date / aply_end_date : ì§€ì› ì‹œì‘ì¼ / ì¢…ë£Œì¼\n",
    "- aplyPrdSeCd : ìƒì‹œì¸ì§€ ì•„ë‹Œì§€? ì´ê±° í•„ìš”í•œê°€.. ì¼ë‹¨ ì ì–´"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98331b32-5944-41b9-9d37-375c8e309de8",
   "metadata": {},
   "source": [
    "í•„ë“œë¡œ ê´€ë¦¬í•  ì½”ë“œëŠ”.. \n",
    "ì‹ ì²­ê¸°ê°„êµ¬ë¶„ì½”ë“œ(ìì—°ì–´ í•„ë“œë¡œ ì¶©ë¶„), ì‚¬ì—…ê¸°ê°„êµ¬ë¶„ì½”ë“œ(ìì—°ì–´ í•„ë“œë¡œ ì¶©ë¶„), ê²°í˜¼ìƒíƒœì½”ë“œ(ìì—°ì–´ í•„ë“œë¡œ ì¶©ë¶„), ì†Œë“ ì¡°ê±´(ìì—°ì–´ í•„ë“œë¡œ ì¶©ë¶„)ì´ê³  \n",
    "\n",
    "í…Œì´ë¸”ë¡œ ê´€ë¦¬í•  ì½”ë“œëŠ”..\n",
    "ì •ì±…ì „ê³µìš”ê±´ì½”ë“œ(o), ì •ì±…ì·¨ì—…ìš”ê±´ì½”ë“œ(o), ì •ì±…í•™ë ¥ìš”ê±´ì½”ë“œ(o), ì •ì±…íŠ¹í™” ìš”ê±´ ì½”ë“œ(o), ì •ì±… ëŒ€ë¶„ë¥˜(o), ì •ì±… ì¤‘ë¶„ë¥˜(o), ì •ì±… í‚¤ì›Œë“œ(o).\n",
    "\n",
    "+ ì§€ì—­ ì½”ë“œ(zip) (o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ab570-25e6-4c94-a2a6-aaf051d73811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_code_tables(cursor):\n",
    "    \"\"\"\n",
    "    ì—‘ì…€ íŒŒì¼ì˜ ê° ì‹œíŠ¸ë¥¼ ì½ì–´ ì½”ë“œ í…Œì´ë¸”ì— ë°ì´í„°ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(\"ğŸš€ ì½”ë“œ í…Œì´ë¸” ë°ì´í„° ì´ê´€ ì‹œì‘...\")\n",
    "\n",
    "    try:\n",
    "        # í…Œì´ë¸”ê³¼ ì‹œíŠ¸ ì´ë¦„, ê·¸ë¦¬ê³  í•´ë‹¹ ì‹œíŠ¸ ë‚´ì˜ ì»¬ëŸ¼ëª…ì„ ë§¤í•‘í•©ë‹ˆë‹¤.\n",
    "        # ì‹œíŠ¸ ì´ë¦„ì€ ì‹¤ì œ ì—‘ì…€ íŒŒì¼ì˜ ì‹œíŠ¸ ì´ë¦„ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "        code_sheets_map = {\n",
    "            'major_codes': ('ì½”ë“œì •ë³´', 'plcyMajorCd', 'ì½”ë“œ', 'ì½”ë“œë‚´ìš©'),\n",
    "            'job_status_codes': ('ì½”ë“œì •ë³´', 'jobCd', 'ì½”ë“œ', 'ì½”ë“œë‚´ìš©'),\n",
    "            'education_level_codes': ('ì½”ë“œì •ë³´', 'schoolCd', 'ì½”ë“œ', 'ì½”ë“œë‚´ìš©'),\n",
    "            'specialization_codes': ('ì½”ë“œì •ë³´', 'sBizCd', 'ì½”ë“œ', 'ì½”ë“œë‚´ìš©'),\n",
    "            'category_codes': ('ì •ì±…ëŒ€ë¶„ë¥˜', None, 'ë²ˆí˜¸', 'ì •ì±…ëŒ€ë¶„ë¥˜ëª…(lclsfNm)'),\n",
    "            'subcategory_codes': ('ì •ì±…ì¤‘ë¶„ë¥˜', None, 'ë²ˆí˜¸', 'ì •ì±…ì¤‘ë¶„ë¥˜ëª…(mclsfNm)'),\n",
    "            'keywords': ('ì •ì±…í‚¤ì›Œë“œ', None, None, 'ì •ì±…í‚¤ì›Œë“œëª…(plcyKywdNm)')\n",
    "        }\n",
    "        \n",
    "        for table_name, (sheet_name, filter_col, code_col, name_col) in code_sheets_map.items():\n",
    "            print(f\"  - í…Œì´ë¸” '{table_name}' ì‘ì—… ì¤‘ (ì‹œíŠ¸: '{sheet_name}')...\")\n",
    "            # read_excelì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì‹œíŠ¸ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "            df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "            \n",
    "            # 'ì½”ë“œì •ë³´' ì‹œíŠ¸ì˜ ê²½ìš°, íŠ¹ì • ë¶„ë¥˜(jobCd ë“±)ë¡œ í•„í„°ë§\n",
    "            if filter_col:\n",
    "                df = df[df['ë¶„ë¥˜'] == filter_col].copy()\n",
    "            \n",
    "            insert_sql = \"\"\n",
    "            # ê° í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì¤€ë¹„ ë° INSERT\n",
    "            if table_name == 'keywords':\n",
    "                insert_sql = f\"INSERT INTO {table_name} (name) VALUES (%s)\"\n",
    "                data_to_insert = [(row[name_col],) for index, row in df.iterrows() if pd.notna(row[name_col])]\n",
    "            else:\n",
    "                insert_sql = f\"INSERT INTO {table_name} (code, name) VALUES (%s, %s)\"\n",
    "                data_to_insert = [(str(row[code_col]), row[name_col]) for index, row in df.iterrows() if pd.notna(row[code_col]) and pd.notna(row[name_col])]\n",
    "            \n",
    "            cursor.executemany(insert_sql, data_to_insert)\n",
    "            print(f\"    âœ… {cursor.rowcount}ê°œ í–‰ ì‚½ì… ì™„ë£Œ.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ğŸš¨ ì˜¤ë¥˜: ì—‘ì…€ íŒŒì¼('{excel_file_path}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì´ë¦„ê³¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ ì˜¤ë¥˜: ì½”ë“œ í…Œì´ë¸” ì´ê´€ ì¤‘ ë¬¸ì œ ë°œìƒ - {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0d03e-e5eb-44aa-83be-187dee5b4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '1234',\n",
    "    'database': 'toyprj4'\n",
    "}\n",
    "\n",
    "# ì—‘ì…€ íŒŒì¼ ì´ë¦„ (ì‚¬ìš©ìë‹˜ì´ ë³€ê²½í•˜ì‹  ì´ë¦„)\n",
    "excel_file_path = './code_table.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a35a3a-7253-44a7-96df-408ea9294e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import \n",
    "connection = None\n",
    "connection = mysql.connector.connect(**db_config)\n",
    "cursor = connection.cursor()\n",
    "print(\"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!\")\n",
    "\n",
    "populate_code_tables(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11da2b4-45e7-4ee0-9ecf-d71f092af519",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "print(\"\\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c0482-327c-4b4f-af51-28e6c70c305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection.rollback()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94014360-9f1f-4a3b-ad49-ad7e1e5a543c",
   "metadata": {},
   "source": [
    "ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸°\n",
    "ì¤‘ë¶„ë¥˜ o ì •ì±…íŠ¹í™” o\n",
    "í‚¤ì›Œë“œ o ëŒ€ë¶„ë¥˜ o\n",
    "\n",
    "ë‚˜ë¨¸ì§„ ê·¸ëƒ¥ ìˆ˜ë™ìœ¼ë¡œ ì‚½ì…í•˜ì. ì–´ì°¨í”¼ ë§ì§€ë„ ì•Šê³ ..\n",
    "\n",
    "ì •ì±… ë°ì´í„° ì´ê´€ì´ë‚˜ ê³ ë¯¼í•  ê²ƒ\n",
    "(ë‚´ì¼ í• ê±°) \n",
    "ëŒ€ì¶© ìƒê°í•˜ê¸°ë¡ .. ì—¬ê¸°ì„œ pandas ì‚¬ìš©í•´ì„œ í•„ìš”í•œ í•„ë“œë§Œ ìš°ì„  ì¶”ì¶œ\n",
    "ë³€í™˜ í•„ìš”í•œ í•„ë“œë“¤ ê°€ê³µ\n",
    "csv(ë˜ëŠ” json)ë¡œ ë§Œë“  ë’¤ dbì— ì‚½ì….\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ddff28d-d508-4bcc-b3fd-2c50c20d4d2a",
   "metadata": {},
   "source": [
    "ì•„.. ë‹¤ì‹œí•´ì•¼í•œë‹¤.. \n",
    "ê·¸ëƒ¥ ì§ì ‘ ì“°ì í•˜..\n",
    "\n",
    "ì¼ë‹¨ ì½”ë“œ í…Œì´ë¸”ì€ ë‹¤ ë§Œë“¤ì—ˆëŠ”ë°.. \n",
    "ë§¤í•‘ í…Œì´ë¸”ì´ ì–¼ë§ˆë‚˜ í•„ìš”í•œì§€ ë‹¤ì‹œ ìƒê°í•´ë³´ì..\n",
    "ëª‡ëª‡ê°œëŠ” í•„ë“œë¡œ ë“¤ì–´ê°€ë„ ë˜ì§€ë§Œ.. ë‹¤ë¥¸ ëª‡ëª‡ê°œëŠ” ë§¤í•‘ìœ¼ë¡œ í’€ì–´ì•¼ í•œë‹¤..\n",
    "ë°ì´í„° ì¢€ í™•ì¸í•´ë³´ì..\n",
    " \n",
    "í•™ë ¥ ì œí•œ ì½”ë“œ => ì½”ë“œ,2ê°œ ì´ìƒì¸ ê²½ìš° ì¡´ì¬ => ì½”ë“œ í…Œì´ë¸”, ë§¤í•‘ í…Œì´ë¸”\n",
    "ì§ì—… ì½”ë“œ => ì½”ë“œ. 2ê°œ ì´ìƒì¸ ê²½ìš° ì¡´ì¬ => ì½”ë“œ í…Œì´ë¸”, ë§¤í•‘ í…Œì´ë¸”\n",
    "ì „ê³µ ì½”ë“œ => ì½”ë“œ, 2ê°œ ì´ìƒì¸ ê²½ìš° ì¡´ì¬ => ì½”ë“œ í…Œì´ë¸”, ë§¤í•‘ íƒœì´ë¸”\n",
    "íŠ¹í™” ì½”ë“œ => ì½”ë“œ, 2ê°œ ì´ìƒì¸ ê²½ìš° ì¡´ì¬ => ì½”ë“œ í…Œì´ë¸”, ë§¤í•‘ í…Œì´ë¸”\n",
    "\n",
    "\n",
    "ì§€ì—­ ì½”ë“œ => ìƒë‹¹íˆ ë‹¤ìˆ˜ì— 5ì. 3ìë¡œ ë¶„ë¦¬ ë° ì½”ë“œ í…Œì´ë¸”, ë§¤í•‘ í…Œì´ë¸”\n",
    "\n",
    "ì •ì±… ëŒ€ë¶„ë¥˜/ì •ì±… ì¤‘ë¶„ë¥˜ => 2ê°œ ì´ìƒ ìˆëŠ” ê²½ìš° í™•ì¸ ì™„ë£Œ. íŠ¹íˆ ì½”ë“œë¡œ ëœ ê²Œ ì•„ë‹ˆê³  ìì—°ì–´ë¡œ ë˜ì–´ìˆìŒ\n",
    "=> ì½”ë“œ í…Œì´ë¸” ì‚­ì œ, only ë§¤í•‘ í…Œì´ë¸”ë§Œ.. ë§¤í•‘ í…Œì´ë¸”ì— ìì—°ì–´ë¡œ ì‘ì„±.\n",
    "\n",
    "ì •ì±… í‚¤ì›Œë“œ ëª… => ë§ˆì°¬ê°€ì§€ë¡œ ìì—°ì–´ í…Œì´ë¸”.. 2ê°œ ì´ìƒ ìˆëŠ” ê²½ìš° ìˆìœ¼ë‹ˆ ë§¤í•‘ í…Œì´ë¸”ë§Œ ì‚¬ìš©í•˜ì. \n",
    "\n",
    "---\n",
    "êµ¬ë¶„ìëŠ” ',' \n",
    "\n",
    "\n",
    "ê²°í˜¼ ìƒíƒœëŠ”.. \n",
    "\n",
    "ë‚´ì¼ ì˜¤ë©´ ì´ê´€ì‘ì—… ê³„ì™ í•˜ì.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fdb44-084f-4806-8aec-9337fed571fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ë°ì´í„°ê°€ ë‹´ê¸´ CSV íŒŒì¼ ê²½ë¡œ\n",
    "csv_file_path = './policy_data.csv' # ì‹¤ì œ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "try:\n",
    "    # CSV íŒŒì¼ì„ DataFrameìœ¼ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "    # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ encoding='utf-8'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    df_raw = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë”© ì„±ê³µ í™•ì¸\n",
    "    print(\"âœ… 1ë‹¨ê³„ ì„±ê³µ: ë°ì´í„° ë¡œë”© ì™„ë£Œ!\")\n",
    "    print(f\"ì „ì²´ ì •ì±… ë°ì´í„° ìˆ˜: {len(df_raw)}ê°œ\")\n",
    "    \n",
    "    # ë°ì´í„° êµ¬ì¡° í™•ì¸ì„ ìœ„í•´ ìƒìœ„ 3ê°œ í–‰ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    print(\"\\n--- ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ ---\")\n",
    "    print(df_raw.head(3))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: '{csv_file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì½ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜: {e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807a17c-19ab-4aad-846a-77caddc8a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ë°ì´í„° ì •ì œ ë° ê°€ê³µ\n",
    "# ìˆ«ì í˜• ë³€í™˜ : ë‚˜ì´, ì†Œë“ ë“± ìˆ«ìì—¬ì•¼ í•˜ëŠ” ì—´ë“¤ì˜ ë°ì´í„° íƒ€ì…ì„ ìˆ«ìë¡œ í™•ì‹¤í•˜ê²Œ ë³€í™˜, ìˆ«ìë¡œ ë³€í™˜ ë¶ˆê°€í•œ ê²½ìš° NaN ì²˜ë¦¬\n",
    "# ë‚ ì§œ í˜• ë³€í™˜ : yymmdd í˜•ì‹ì˜ ë‚ ì§œë¥»ë¦‰ã„¹ ì‹¤ì œ ë‚ ì§œ í˜•ìœ¼ë¡œ ë³€í™˜í•˜ê³ , êµ¬ê°„ ì •ë³´ì˜ ê²½ìš° ë¶„ë¦¬.\n",
    "\n",
    "# --- 2.1. ì»¬ëŸ¼ ì„ íƒ ë° ì´ë¦„ ë³€ê²½ (ìˆ˜ì •) ---\n",
    "column_mapping = {\n",
    "    'plcyNo': 'policy_id',\n",
    "    'plcyNm': 'policy_name',\n",
    "    'plcyExplnCn': 'policy_summary',\n",
    "    'refUrlAddr1': 'source_url',\n",
    "    'sprtTrgtMinAge': 'min_age',\n",
    "    'sprtTrgtMaxAge': 'max_age',\n",
    "    'earnMinAmt': 'income_min',\n",
    "    'earnMaxAmt': 'income_max',\n",
    "    'bizPrdBgngYmd': 'biz_start_date',\n",
    "    'bizPrdEndYmd': 'biz_end_date',\n",
    "    'aplyYmd': 'aply_period',\n",
    "    'mrgSttsCd': 'marriage_status',\n",
    "    'aplyPrdSeCd': 'application_status', \n",
    "    'jobCd': 'job_status_codes',\n",
    "    'schoolCd': 'education_level_codes',\n",
    "    'plcyMajorCd': 'major_codes',\n",
    "    'plcyKywdNm': 'keywords',\n",
    "    'zipCd': 'region_codes',\n",
    "    'lclsfNm': 'category_names',\n",
    "    'mclsfNm': 'subcategory_names',\n",
    "    'rgtrInstCdNm: Operation_Inst'\n",
    "}\n",
    "\n",
    "df_selected = df_raw[list(column_mapping.keys())].copy()\n",
    "df_processed = df_selected.rename(columns=column_mapping)\n",
    "\n",
    "# --- 2.2. ìˆ«ì í˜•ì‹ ë³€í™˜ (ë³€ê²½ ì—†ìŒ) ---\n",
    "numeric_cols = ['min_age', 'max_age', 'income_min', 'income_max']\n",
    "for col in numeric_cols:\n",
    "    df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "    df_processed[col] = df_processed[col].replace(0, np.nan)\n",
    "\n",
    "# --- 2.3. ë‚ ì§œ í˜•ì‹ ë³€í™˜ (ë³€ê²½ ì—†ìŒ) ---\n",
    "def to_datetime_safe(date_str):\n",
    "    if pd.isna(date_str) or not isinstance(date_str, str) or not date_str.strip():\n",
    "        return pd.NaT\n",
    "    return pd.to_datetime(date_str, format='%Y%m%d', errors='coerce')\n",
    "\n",
    "def parse_apply_period(period_str):\n",
    "    if pd.isna(period_str) or '~' not in str(period_str):\n",
    "        return pd.NaT, pd.NaT\n",
    "    try:\n",
    "        start_str, end_str = [s.strip() for s in period_str.split('~')]\n",
    "        return to_datetime_safe(start_str), to_datetime_safe(end_str)\n",
    "    except ValueError:\n",
    "        return pd.NaT, pd.NaT\n",
    "\n",
    "df_processed['biz_start_date'] = df_processed['biz_start_date'].apply(to_datetime_safe)\n",
    "df_processed['biz_end_date'] = df_processed['biz_end_date'].apply(to_datetime_safe)\n",
    "df_processed[['aply_start_date', 'aply_end_date']] = df_processed['aply_period'].apply(\n",
    "    lambda x: pd.Series(parse_apply_period(x))\n",
    ")\n",
    "df_processed = df_processed.drop(columns=['aply_period'])\n",
    "\n",
    "print(\"âœ… ìˆ˜ì •ëœ 2ë‹¨ê³„ ì„±ê³µ: `application_status` í¬í•¨í•˜ì—¬ ì •ì œ ì™„ë£Œ!\")\n",
    "print(df_processed[['policy_id', 'application_status']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889555a-b37e-432c-90ed-17acd9519fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. policies í…Œì´ë¸”ìš© ë°ì´í„° í”„ë ˆì„ ìƒì„±\n",
    "\n",
    "# 1. 'policies' í…Œì´ë¸” ì»¬ëŸ¼ ëª©ë¡ ì •ì˜ (ìˆ˜ì •)\n",
    "policy_table_cols = [\n",
    "    'policy_id',\n",
    "    'policy_name',\n",
    "    'policy_summary',\n",
    "    'Operation_Inst',\n",
    "    'source_url',\n",
    "    'min_age',\n",
    "    'max_age',\n",
    "    'income_min',\n",
    "    'income_max',\n",
    "    'biz_start_date',\n",
    "    'biz_end_date',\n",
    "    'aply_start_date',\n",
    "    'aply_end_date',\n",
    "    'marriage_status',\n",
    "    'application_status' \n",
    "]\n",
    "\n",
    "# 2. df_processedì—ì„œ í•´ë‹¹ ì»¬ëŸ¼ë“¤ë§Œ ì„ íƒí•˜ì—¬ ìµœì¢… policies_df ìƒì„±\n",
    "policies_df = df_processed[policy_table_cols].copy()\n",
    "\n",
    "# 3. ê²°ê³¼ í™•ì¸\n",
    "print(\"\\nâœ… ìˆ˜ì •ëœ 3ë‹¨ê³„ ì„±ê³µ: `application_status` í¬í•¨í•˜ì—¬ `policies_df` ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"\\n--- policies_df ì •ë³´ ---\")\n",
    "policies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ad08c-340e-4ce6-96b3-411c3d90e9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ìˆœì„œ ì¬ì •ë ¬(DB ìŠ¤í‚¤ë§ˆ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ)\n",
    "# (ì„ íƒ ì‚¬í•­) DB ìŠ¤í‚¤ë§ˆ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬\n",
    "db_schema_order = [\n",
    "    'policy_id', 'min_age', 'max_age', 'income_min', 'income_max',\n",
    "    'biz_start_date', 'biz_end_date', 'aply_start_date', 'aply_end_date',\n",
    "    'application_status', 'marriage_status', 'policy_name', \n",
    "    'policy_summary', 'source_url'\n",
    "]\n",
    "policies_df = policies_df[db_schema_order]\n",
    "\n",
    "# ì¬ì •ë ¬ëœ ìˆœì„œ í™•ì¸\n",
    "print(policies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db284e4-a981-4635-b415-cdcb3f00ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.info()\n",
    "\n",
    "# df_processedì—ì„œ 'keywords' ì—´ì´ ë¹„ì–´ìˆì§€ ì•Šì€ í–‰ì˜ ê°œìˆ˜ë¥¼ ì„¸ì–´ë´…ë‹ˆë‹¤.\n",
    "policies_with_keywords = df_processed['keywords'].notna().sum()\n",
    "\n",
    "print(f\"ì „ì²´ {len(df_processed)}ê°œ ì •ì±… ì¤‘, í‚¤ì›Œë“œê°€ í• ë‹¹ëœ ì •ì±…ì˜ ìˆ˜: {policies_with_keywords}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56b1a1-039d-4f7d-ae9e-500d271ff2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. ë§¤í•‘ í…Œì´ë¸”ìš© ë°ì´í„° í”„ë ˆì„ ìƒì„±\n",
    "\n",
    "\n",
    "# 1. ë§¤í•‘ í…Œì´ë¸” ìƒì„±ì„ ìœ„í•œ ë²”ìš© í•¨ìˆ˜ ì •ì˜\n",
    "def create_mapping_df(df, id_col, value_col, new_value_col_name):\n",
    "    \"\"\"\n",
    "    ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’ì„ ê°€ì§„ ì»¬ëŸ¼ì„ ë¶„ë¦¬í•˜ì—¬,\n",
    "    ì •ì±… IDì™€ ê°’ì´ 1:1ë¡œ ë§¤í•‘ë˜ëŠ” 'ê¸¸ì­‰í•œ' ë°ì´í„°í”„ë ˆì„ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "    \n",
    "    :param df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„ (df_processed)\n",
    "    :param id_col: ê¸°ì¤€ ID ì»¬ëŸ¼ëª… ('policy_id')\n",
    "    :param value_col: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’ì´ ìˆëŠ” ì»¬ëŸ¼ëª…\n",
    "    :param new_value_col_name: ìµœì¢… ë§¤í•‘ í…Œì´ë¸”ì˜ ê°’ ì»¬ëŸ¼ëª…\n",
    "    :return: ë§¤í•‘ í…Œì´ë¸”ìš© ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    # 1. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³ , ê°’ì´ ë¹„ì–´ìˆëŠ” í–‰ì€ ì œì™¸\n",
    "    temp_df = df[[id_col, value_col]].dropna(subset=[value_col])\n",
    "    \n",
    "    # 2. ì‰¼í‘œ(,)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°’ì„ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¦\n",
    "    temp_df[value_col] = temp_df[value_col].str.split(',')\n",
    "    \n",
    "    # 3. .explode() í•¨ìˆ˜ë¡œ ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ ë³„ë„ì˜ í–‰ìœ¼ë¡œ í¼ì¹¨\n",
    "    mapping_df = temp_df.explode(value_col)\n",
    "    \n",
    "    # 4. ê° ê°’ì˜ ì•ë’¤ ê³µë°± ì œê±°\n",
    "    mapping_df[value_col] = mapping_df[value_col].str.strip()\n",
    "    \n",
    "    # 5. ìµœì¢… ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ (ì˜ˆ: value_col -> keyword_name)\n",
    "    mapping_df = mapping_df.rename(columns={value_col: new_value_col_name})\n",
    "    \n",
    "    # 6. ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "    mapping_df = mapping_df.reset_index(drop=True)\n",
    "    \n",
    "    return mapping_df\n",
    "\n",
    "# 2. 'keywords' ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ 'policy_keywords' ë§¤í•‘ í…Œì´ë¸” ìƒì„±\n",
    "policy_keywords_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='keywords', \n",
    "    new_value_col_name='keyword_name' # DB ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì´ë¦„ ì§€ì •\n",
    ")\n",
    "\n",
    "# 3. ê²°ê³¼ í™•ì¸\n",
    "print(\"âœ… 4-1ë‹¨ê³„ ì„±ê³µ: `policy_keywords_df` ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"ìƒì„±ëœ í‚¤ì›Œë“œ ë§¤í•‘ ìˆ˜: {len(policy_keywords_df)}ê°œ\")\n",
    "\n",
    "print(\"\\n--- policy_keywords_df ë°ì´í„° ìƒ˜í”Œ ---\")\n",
    "print(policy_keywords_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafc605-ac15-4317-ac97-d05b41c4fd7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"âœ… 4-2ë‹¨ê³„ ì‹œì‘: ë‚˜ë¨¸ì§€ ë§¤í•‘ í…Œì´ë¸”ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n\")\n",
    "\n",
    "# 1. ì·¨ì—… ìƒíƒœ(job_status) ë§¤í•‘ í…Œì´ë¸” ìƒì„±\n",
    "policy_job_status_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='job_status_codes', \n",
    "    new_value_col_name='job_status_code'\n",
    ")\n",
    "print(\"--- `policy_job_status_df` ìƒì„± ì™„ë£Œ ---\")\n",
    "print(policy_job_status_df.head())\n",
    "\n",
    "\n",
    "# 2. í•™ë ¥(education_levels) ë§¤í•‘ í…Œì´ë¸” ìƒì„±\n",
    "policy_education_levels_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='education_level_codes', \n",
    "    new_value_col_name='education_level_code'\n",
    ")\n",
    "print(\"\\n--- `policy_education_levels_df` ìƒì„± ì™„ë£Œ ---\")\n",
    "print(policy_education_levels_df.head())\n",
    "\n",
    "\n",
    "# 3. ì „ê³µ(majors) ë§¤í•‘ í…Œì´ë¸” ìƒì„±\n",
    "policy_majors_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='major_codes', \n",
    "    new_value_col_name='major_code'\n",
    ")\n",
    "print(\"\\n--- `policy_majors_df` ìƒì„± ì™„ë£Œ ---\")\n",
    "print(policy_majors_df.head())\n",
    "\n",
    "\n",
    "# 4. ì§€ì—­(regions) ë§¤í•‘ í…Œì´ë¸” ìƒì„±\n",
    "policy_regions_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='region_codes', \n",
    "    new_value_col_name='region_code'\n",
    ")\n",
    "print(\"\\n--- `policy_regions_df` ìƒì„± ì™„ë£Œ ---\")\n",
    "print(policy_regions_df.head())\n",
    "\n",
    "\n",
    "# 5. ì¹´í…Œê³ ë¦¬(categories) ë§¤í•‘ í…Œì´ë¸” ìƒì„±\n",
    "policy_categories_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='category_names', \n",
    "    new_value_col_name='category_name'\n",
    ")\n",
    "print(\"\\n--- `policy_categories_df` ìƒì„± ì™„ë£Œ ---\")\n",
    "print(policy_categories_df.head())\n",
    "\n",
    "\n",
    "# 6. ì„œë¸Œì¹´í…Œê³ ë¦¬(subcategories) ë§¤í•‘ í…Œì´ë¸” ìƒì„±\n",
    "policy_subcategories_df = create_mapping_df(\n",
    "    df=df_processed, \n",
    "    id_col='policy_id', \n",
    "    value_col='subcategory_names', \n",
    "    new_value_col_name='subcategory_name'\n",
    ")\n",
    "print(\"\\n--- `policy_subcategories_df` ìƒì„± ì™„ë£Œ ---\")\n",
    "print(policy_subcategories_df.head())\n",
    "\n",
    "print(\"\\n\\nâœ… 4ë‹¨ê³„ ì„±ê³µ: ëª¨ë“  ë§¤í•‘ í…Œì´ë¸”ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7347c-b812-41fe-829d-c8e42e8a7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ì… ë””ë²„ê¹…ì„ ìœ„í•œ í™•ì¸ìš© ì½›,\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ì—‘ì…€ íŒŒì¼ ê²½ë¡œ\n",
    "CODE_EXCEL_PATH = './code_table.xlsx'\n",
    "\n",
    "try:\n",
    "    # ì—‘ì…€ íŒŒì¼ì˜ 'ì½”ë“œì •ë³´' ì‹œíŠ¸ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "    df_codes_debug = pd.read_excel(CODE_EXCEL_PATH, sheet_name='ì½”ë“œì •ë³´')\n",
    "\n",
    "    print(\"--- 1. ì‹¤ì œ ì»¬ëŸ¼ ì´ë¦„ í™•ì¸ ---\")\n",
    "    print(df_codes_debug.columns.tolist())\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "    # 'ë¶„ë¥˜'ë¼ëŠ” ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆë‹¤ë©´ ê·¸ ì•ˆì˜ ê³ ìœ í•œ ê°’ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    if 'ë¶„ë¥˜' in df_codes_debug.columns:\n",
    "        print(\"--- 2. 'ë¶„ë¥˜' ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ í™•ì¸ ---\")\n",
    "        # ffill()ì„ ë¨¼ì € ì ìš©í•´ì„œ ë¹„ì–´ìˆëŠ” ì…€ì„ ì±„ìš´ í›„ ê³ ìœ ê°’ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "        unique_values = df_codes_debug['ë¶„ë¥˜'].ffill().unique()\n",
    "        print(unique_values)\n",
    "    else:\n",
    "        print(\">>> 'ë¶„ë¥˜'ë¼ëŠ” ì´ë¦„ì˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "    \n",
    "    print(\"--- 3. íŒŒì¼ ìƒìœ„ 5ì¤„ ë‚´ìš© í™•ì¸ ---\")\n",
    "    print(df_codes_debug.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ì˜¤ë¥˜: '{CODE_EXCEL_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e75706-76a0-4218-a699-36693f625acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04785eeb-ac81-4e61-a26c-db1c077ae7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "\n",
    "# --- ì„¤ì • ---\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "POLICY_DATA_PATH = './policy_data.csv'\n",
    "CODE_EXCEL_PATH = './code_table.xlsx'\n",
    "\n",
    "# DB ì—°ê²° ì •ë³´ (!!!ë°˜ë“œì‹œ ìˆ˜ì •!!!)\n",
    "DB_USER = \"root\"\n",
    "DB_PASSWORD = \"1234\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"3306\"\n",
    "DB_NAME = \"toyprj4\"\n",
    "DB_URL = f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "\n",
    "# --- í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ë³€ê²½ ì—†ìŒ) ---\n",
    "def to_datetime_safe(date_str):\n",
    "    if pd.isna(date_str) or not isinstance(date_str, str) or not date_str.strip():\n",
    "        return pd.NaT\n",
    "    return pd.to_datetime(date_str, format='%Y%m%d', errors='coerce')\n",
    "\n",
    "def parse_apply_period(period_str):\n",
    "    if pd.isna(period_str) or '~' not in str(period_str):\n",
    "        return pd.NaT, pd.NaT\n",
    "    try:\n",
    "        start_str, end_str = [s.strip() for s in period_str.split('~')]\n",
    "        return to_datetime_safe(start_str), to_datetime_safe(end_str)\n",
    "    except ValueError:\n",
    "        return pd.NaT, pd.NaT\n",
    "\n",
    "def create_mapping_df(df, id_col, value_col, new_value_col_name):\n",
    "    temp_df = df[[id_col, value_col]].dropna(subset=[value_col])\n",
    "    if temp_df.empty:\n",
    "        return pd.DataFrame(columns=[id_col, new_value_col_name])\n",
    "    temp_df[value_col] = temp_df[value_col].astype(str).str.split(',')\n",
    "    mapping_df = temp_df.explode(value_col)\n",
    "    mapping_df[value_col] = mapping_df[value_col].str.strip()\n",
    "    mapping_df = mapping_df.rename(columns={value_col: new_value_col_name})\n",
    "    return mapping_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- ë©”ì¸ ETL ë¡œì§ ---\n",
    "def run_etl():\n",
    "    \"\"\"ì „ì²´ ETL í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    # --- 1. ì¶”ì¶œ (Extract) ---\n",
    "    try:\n",
    "        df_raw = pd.read_csv(POLICY_DATA_PATH, encoding='utf-8')\n",
    "        df_codes = pd.read_excel(CODE_EXCEL_PATH, sheet_name='ì½”ë“œì •ë³´', dtype={'ì½”ë“œ': str})\n",
    "        logging.info(f\"âœ… 1ë‹¨ê³„ ì„±ê³µ: ë°ì´í„° ë° ì—‘ì…€ ì½”ë“œ ì‹œíŠ¸ ë¡œë“œ ì™„ë£Œ.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({e})\")\n",
    "        return\n",
    "\n",
    "    # --- 2. ë³€í™˜ (Transform) ---\n",
    "    # 2.1. ì½”ë“œ-ìì—°ì–´ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "    code_map = {}\n",
    "    df_codes['ë¶„ë¥˜'] = df_codes['ë¶„ë¥˜'].ffill() \n",
    "    df_codes['ì½”ë“œ'] = df_codes['ì½”ë“œ'].str.zfill(7)\n",
    "    \n",
    "    code_map['marriage_status'] = df_codes[df_codes['ë¶„ë¥˜'] == 'mrgSttsCd'].set_index('ì½”ë“œ')['ì½”ë“œë‚´ìš©'].to_dict()\n",
    "    code_map['application_status'] = df_codes[df_codes['ë¶„ë¥˜'] == 'aplyPrdSeCd'].set_index('ì½”ë“œ')['ì½”ë“œë‚´ìš©'].to_dict()\n",
    "    logging.info(\"ì½”ë“œ-ìì—°ì–´ ë§¤í•‘ ìƒì„± ì™„ë£Œ.\")\n",
    "    \n",
    "    # 2.2. ê¸°ë³¸ ì •ì œ\n",
    "    column_mapping = {\n",
    "        'plcyNo': 'policy_id', 'plcyNm': 'policy_name', 'plcyExplnCn': 'policy_summary',\n",
    "        'refUrlAddr1': 'source_url', 'sprtTrgtMinAge': 'min_age', 'sprtTrgtMaxAge': 'max_age',\n",
    "        'earnMinAmt': 'income_min', 'earnMaxAmt': 'income_max', 'bizPrdBgngYmd': 'biz_start_date',\n",
    "        'bizPrdEndYmd': 'biz_end_date', 'aplyYmd': 'aply_period', 'mrgSttsCd': 'marriage_status',\n",
    "        'aplyPrdSeCd': 'application_status', 'jobCd': 'job_status_codes', 'schoolCd': 'education_level_codes',\n",
    "        'plcyMajorCd': 'major_codes', 'sbizCd': 'specialization_codes', 'plcyKywdNm': 'keywords',\n",
    "        'zipCd': 'region_codes', 'lclsfNm': 'category_names', 'mclsfNm': 'subcategory_names',\n",
    "        'rgtrInstCdNm': 'operation_inst' # rgtrInstCdNm ì»¬ëŸ¼ ì¶”ê°€\n",
    "    }\n",
    "    df_processed = df_raw[list(column_mapping.keys())].copy().rename(columns=column_mapping)\n",
    "\n",
    "    # 2.3. ì½”ë“œë¥¼ ìì—°ì–´ë¡œ ë³€í™˜\n",
    "    def code_to_natural(series, mapping_dict):\n",
    "        \"\"\"ìˆ«ì/ë¬¸ìì—´ ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ìì—°ì–´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "        # 1. ë¹„ì–´ìˆëŠ” ê°’(NaN)ì€ ê·¸ëŒ€ë¡œ ë‘ \n",
    "        # 2. pd.to_numericìœ¼ë¡œ ìˆ«ì ë³€í™˜ ì‹œë„, ì‹¤íŒ¨ ì‹œ NaN\n",
    "        # 3. ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ .0 ì œê±°\n",
    "        # 4. ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "        # 5. 7ìë¦¬ë¡œ ë§ì¶¤\n",
    "        # 6. ìµœì¢… ë§¤í•‘\n",
    "        return pd.to_numeric(series, errors='coerce').astype('Int64').astype(str).str.zfill(7).map(mapping_dict)\n",
    "\n",
    "    df_processed['marriage_status'] = code_to_natural(df_processed['marriage_status'], code_map['marriage_status'])\n",
    "    df_processed['application_status'] = code_to_natural(df_processed['application_status'], code_map['application_status'])\n",
    "    logging.info(\"ê²°í˜¼ìƒíƒœ, ì‹ ì²­ìƒíƒœ ì½”ë“œ -> ìì—°ì–´ ë³€í™˜ ì™„ë£Œ.\")\n",
    "\n",
    "    # 2.4. ìˆ«ì ë° ë‚ ì§œ ë³€í™˜\n",
    "    numeric_cols = ['min_age', 'max_age', 'income_min', 'income_max']\n",
    "    for col in numeric_cols:\n",
    "        df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce').replace(0, np.nan)\n",
    "\n",
    "    df_processed['biz_start_date'] = df_processed['biz_start_date'].apply(to_datetime_safe)\n",
    "    df_processed['biz_end_date'] = df_processed['biz_end_date'].apply(to_datetime_safe)\n",
    "    df_processed[['aply_start_date', 'aply_end_date']] = df_processed['aply_period'].apply(lambda x: pd.Series(parse_apply_period(x)))\n",
    "    df_processed = df_processed.drop(columns=['aply_period'])\n",
    "    logging.info(\"âœ… 2ë‹¨ê³„ ì„±ê³µ: ì „ì²´ ë°ì´í„° ì •ì œ ë° ê°€ê³µ ì™„ë£Œ.\")\n",
    "\n",
    "    # --- 3. ë³€í™˜ (Transform) - `policies` í…Œì´ë¸”ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± ---\n",
    "    policy_table_cols = [\n",
    "        'policy_id', 'policy_name', 'policy_summary', 'source_url', 'min_age', 'max_age',\n",
    "        'income_min', 'income_max', 'biz_start_date', 'biz_end_date', 'aply_start_date',\n",
    "        'aply_end_date', 'marriage_status', 'application_status',\n",
    "        'operation_inst' # `policies` í…Œì´ë¸”ì— ì¶”ê°€ëœ ì»¬ëŸ¼\n",
    "    ]\n",
    "    policies_df = df_processed[policy_table_cols].copy()\n",
    "    logging.info(\"âœ… 3ë‹¨ê³„ ì„±ê³µ: `policies` í…Œì´ë¸”ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± ì™„ë£Œ.\")\n",
    "\n",
    "    # --- 4. ë³€í™˜ (Transform) - ë§¤í•‘ í…Œì´ë¸”ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± ---\n",
    "    policy_keywords_df = create_mapping_df(df_processed, 'policy_id', 'keywords', 'keyword_name')\n",
    "    policy_job_status_df = create_mapping_df(df_processed, 'policy_id', 'job_status_codes', 'job_status_code')\n",
    "    policy_education_levels_df = create_mapping_df(df_processed, 'policy_id', 'education_level_codes', 'education_level_code')\n",
    "    policy_majors_df = create_mapping_df(df_processed, 'policy_id', 'major_codes', 'major_code')\n",
    "    policy_regions_df = create_mapping_df(df_processed, 'policy_id', 'region_codes', 'region_code')\n",
    "    policy_categories_df = create_mapping_df(df_processed, 'policy_id', 'category_names', 'category_name')\n",
    "    policy_subcategories_df = create_mapping_df(df_processed, 'policy_id', 'subcategory_names', 'subcategory_name')\n",
    "    policy_specializations_df = create_mapping_df(df_processed, 'policy_id', 'specialization_codes', 'specialization_code')\n",
    "    logging.info(\"âœ… 4ë‹¨ê³„ ì„±ê³µ: ëª¨ë“  ë§¤í•‘ í…Œì´ë¸”ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± ì™„ë£Œ.\")\n",
    "\n",
    "    # --- 5. ì ì¬ (Load) ---\n",
    "    try:\n",
    "        engine = create_engine(DB_URL)\n",
    "        logging.info(f\"ë°ì´í„°ë² ì´ìŠ¤ '{DB_NAME}'ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        dataframes_to_load = {\n",
    "            'policies': policies_df,\n",
    "            'policy_keywords': policy_keywords_df,\n",
    "            'policy_job_status': policy_job_status_df,\n",
    "            'policy_education_levels': policy_education_levels_df,\n",
    "            'policy_majors': policy_majors_df,\n",
    "            'policy_regions': policy_regions_df,\n",
    "            'policy_categories': policy_categories_df,\n",
    "            'policy_subcategories': policy_subcategories_df,\n",
    "            'policy_specializations': policy_specializations_df\n",
    "        }\n",
    "\n",
    "        for table_name, df in dataframes_to_load.items():\n",
    "            df.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "            logging.info(f\"-> í…Œì´ë¸” '{table_name}'ì— {len(df)}ê°œ í–‰ ì ì¬ ì™„ë£Œ.\")\n",
    "        \n",
    "        logging.info(\"ğŸ‰ 5ë‹¨ê³„ ì„±ê³µ: ëª¨ë“  ë°ì´í„° ì ì¬ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ 5ë‹¨ê³„ ì˜¤ë¥˜: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë˜ëŠ” ì ì¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4a3d5-600e-4cc1-b721-f1f0653b5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "POLICY_DATA_PATH = './policy_data.csv'\n",
    "CODE_EXCEL_PATH = './code_table.xlsx'\n",
    "\n",
    "try:\n",
    "    # 1. ê° íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "    df_raw_debug = pd.read_csv(POLICY_DATA_PATH, encoding='utf-8')\n",
    "    df_codes_debug = pd.read_excel(CODE_EXCEL_PATH, sheet_name='ì½”ë“œì •ë³´', dtype={'ì½”ë“œ': str})\n",
    "\n",
    "    # --- marriage_status ë§¤í•‘ ê³¼ì •ë§Œ ì§‘ì¤‘ ë¶„ì„ ---\n",
    "\n",
    "    # 2. ì½”ë“œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "    df_codes_debug['ë¶„ë¥˜'] = df_codes_debug['ë¶„ë¥˜'].ffill()\n",
    "    df_codes_debug['ì½”ë“œ'] = df_codes_debug['ì½”ë“œ'].str.zfill(7)\n",
    "    \n",
    "    marriage_map = df_codes_debug[df_codes_debug['ë¶„ë¥˜'] == 'mrgSttsCd'].set_index('ì½”ë“œ')['ì½”ë“œë‚´ìš©'].to_dict()\n",
    "\n",
    "    print(\"--- 1. ìƒì„±ëœ ê²°í˜¼ìƒíƒœ(marriage_status) ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ---\")\n",
    "    print(marriage_map)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "    # 3. ì›ë³¸ ë°ì´í„°ì˜ 'mrgSttsCd' ê°’ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    #    ê°’ì´ ë¹„ì–´ìˆì§€ ì•Šì€ ìƒ˜í”Œ 5ê°œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    sample_codes = df_raw_debug['mrgSttsCd'].dropna().head(5)\n",
    "    \n",
    "    print(\"--- 2. ì›ë³¸ ë°ì´í„°ì˜ 'mrgSttsCd' ìƒ˜í”Œ ---\")\n",
    "    print(sample_codes)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    \n",
    "    # 4. ì´ ìƒ˜í”Œë“¤ì´ ì–´ë–»ê²Œ ë³€í™˜ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    print(\"--- 3. ìƒ˜í”Œ ì½”ë“œ ë³€í™˜ ê³¼ì • ë° ë§¤í•‘ ê²°ê³¼ ---\")\n",
    "    for code in sample_codes:\n",
    "        # ì›ë³¸ ê°’ì„ ë¬¸ìì—´ë¡œ ë°”ê¾¸ê³  7ìë¦¬ë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "        processed_code = str(code).zfill(7)\n",
    "        # ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ì—ì„œ ê°’ì„ ì°¾ì•„ë´…ë‹ˆë‹¤.\n",
    "        mapped_value = marriage_map.get(processed_code, \">>> ë§¤í•‘ ì‹¤íŒ¨! <<<\")\n",
    "        \n",
    "        print(f\"ì›ë³¸: {code}  ->  ë³€í™˜ í›„: '{processed_code}'  ->  ë§¤í•‘ ê²°ê³¼: {mapped_value}\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({e})\")\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_spike",
   "language": "python",
   "name": "langchain_spike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
