{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6fdcb1-c673-496f-adbd-350be7cb4006",
   "metadata": {
    "tags": []
   },
   "source": [
    "흠.. 일단 내가 아는 선에서 다 해보자.\n",
    "\n",
    "1. 먼저 데이터 한 번 준비해보자. 희망적인 점은, api 사용해서 json 혹은 txt 형태로 받아올 수 있다는 점이다. json으로 받아오고, dict로 변환한 다음에 필요한 부분만 만들어서.. 일단 대충 이렇게 생각은 든다.\n",
    "\n",
    "2. 그러면.. 메타데이터 처리는 어떻게 해야할까? 메타데이터 메타데이터 메타데이터.. 메타데이터는 답변의 신뢰도 체감을 높일 수 있는 UX 상의 장치이기도 하다. pdf여러개.. pdf의 페이지도 중요하겠고, 제목도 중요하겠고.. doc loader 및 split 과정에서 이들이 어떻게 처리되는지 확인해 볼 필요가 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d596a-cf61-45c1-bf7f-7506bf39419a",
   "metadata": {
    "tags": []
   },
   "source": [
    "API로 정책들을 받아왔을 때, 어떤 것들이 오는지 확인해보았다.\n",
    "그런 고민이 있었다. 이 답을 그대로 청킹하고 임베딩 하는 순간, \n",
    "정책 본문과 일종의 메타데이터로 존재해야 할 제목, 정책 번호 등이 잘리는 것 아닌가?\n",
    "그렇다면, 이는 별개의 벡터일텐데 의미가 있을까? 다른 어떤 과정이 더 필요하지 않을까?\n",
    "\n",
    "=> 선별과 조합이 필요하다. 수많은 응답 필드 중 필요한 것들을 뽑아내고, 이를 메타데이터로 삽입하자.\n",
    "=> metadata가 되어야 할 것들과 content가 되어야할 것들을 구분하자."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8419b03-4369-4810-bf28-322afd86bb50",
   "metadata": {
    "tags": []
   },
   "source": [
    "3. 출력결과\n",
    "오픈 API 출력결과 - 항목, 타입, 설명, OPEN API DOC 목록\n",
    "항목\t타입\t설명\t비고\n",
    "<youthPolicyList>\t\t\t</youthPolicyList>\n",
    "<plcyNo>\tString\t정책번호\t</plcyNo>\n",
    "<bscPlanCycl>\tString\t기본계획차수\t</bscPlanCycl>\n",
    "<bscPlanPlcyWayNo>\tString\t기본계획정책방향번호\t</bscPlanPlcyWayNo>\n",
    "<bscPlanFcsAsmtNo>\tString\t기본계획중점과제번호\t</bscPlanFcsAsmtNo>\n",
    "<bscPlanAsmtNo>\tString\t기본계획과제번호\t</bscPlanAsmtNo>\n",
    "<pvsnInstGroupCd>\tString\t제공기관그룹코드\t</pvsnInstGroupCd>\n",
    "<plcyPvsnMthdCd>\tString\t정책제공방법코드\t</plcyPvsnMthdCd>\n",
    "<plcyAprvSttsCd>\tString\t정책승인상태코드\t</plcyAprvSttsCd>\n",
    "<plcyNm>\tString\t정책명\t</plcyNm>\n",
    "<plcyKywdNm>\tString\t정책키워드명\t</plcyKywdNm>\n",
    "<plcyExplnCn>\tString\t정책설명내용\t</plcyExplnCn>\n",
    "<lclsfNm>\tString\t정책대분류명\t</lclsfNm>\n",
    "<mclsfNm>\tString\t정책중분류명\t</mclsfNm>\n",
    "<plcySprtCn>\tString\t정책지원내용\t</plcySprtCn>\n",
    "<sprvsnInstCd>\tString\t주관기관코드\t</sprvsnInstCd>\n",
    "<sprvsnInstCdNm>\tString\t주관기관코드명\t</sprvsnInstCdNm>\n",
    "<sprvsnInstPicNm>\tString\t주관기관담당자명\t</sprvsnInstPicNm>\n",
    "<operInstCd>\tString\t운영기관코드\t</operInstCd>\n",
    "<operInstCdNm>\tString\t운영기관코드명\t</operInstCdNm>\n",
    "<operInstPicNm>\tString\t운영기관담당자명\t</operInstPicNm>\n",
    "<sprtSclLmtYn>\tString\t지원규모제한여부\t</sprtSclLmtYn>\n",
    "<aplyPrdSeCd>\tString\t신청기간구분코드\t</aplyPrdSeCd>\n",
    "<bizPrdSeCd>\tString\t사업기간구분코드\t</bizPrdSeCd>\n",
    "<bizPrdBgngYmd>\tString\t사업기간시작일자\t</bizPrdBgngYmd>\n",
    "<bizPrdEndYmd>\tString\t사업기간종료일자\t</bizPrdEndYmd>\n",
    "<bizPrdEtcCn>\tString\t사업기간기타내용\t</bizPrdEtcCn>\n",
    "<plcyAplyMthdCn>\tString\t정책신청방법내용\t</plcyAplyMthdCn>\n",
    "<srngMthdCn>\tString\t심사방법내용\t</srngMthdCn>\n",
    "<aplyUrlAddr>\tString\t신청URL주소\t</aplyUrlAddr>\n",
    "<sbmsnDcmntCn>\tString\t제출서류내용\t</sbmsnDcmntCn>\n",
    "<etcMttrCn>\tString\t기타사항내용\t</etcMttrCn>\n",
    "<refUrlAddr1>\tString\t참고URL주소\t</refUrlAddr1>\n",
    "<refUrlAddr2>\tString\t참고URL주소\t</refUrlAddr2>\n",
    "<sprtSclCnt>\tString\t지원규모수\t</sprtSclCnt>\n",
    "<sprtArvlSeqYn>\tString\t지원도착순서여부\t</sprtArvlSeqYn>\n",
    "<sprtTrgtMinAge>\tString\t지원대상최소연령\t</sprtTrgtMinAge>\n",
    "<sprtTrgtMaxAge>\tString\t지원대상최대연령\t</sprtTrgtMaxAge>\n",
    "<sprtTrgtAgeLmtYn>\tString\t지원대상연령제한여부\t</sprtTrgtAgeLmtYn>\n",
    "<mrgSttsCd>\tString\t결혼상태코드\t</mrgSttsCd>\n",
    "<earnCndSeCd>\tString\t소득조건구분코드\t</earnCndSeCd>\n",
    "<earnMinAmt>\tString\t소득최소금액\t</earnMinAmt>\n",
    "<earnMaxAmt>\tString\t소득최대금액\t</earnMaxAmt>\n",
    "<earnEtcCn>\tString\t소득기타내용\t</earnEtcCn>\n",
    "<addAplyQlfcCndCn>\tString\t추가신청자격조건내용\t</addAplyQlfcCndCn>\n",
    "<ptcpPrpTrgtCn>\tString\t참여제안대상내용\t</ptcpPrpTrgtCn>\n",
    "<inqCnt>\tString\t조회수\t</inqCnt>\n",
    "<rgtrInstCd>\tString\t등록자기관코드\t</rgtrInstCd>\n",
    "<rgtrInstCdNm>\tString\t등록자기관코드명\t</rgtrInstCdNm>\n",
    "<rgtrUpInstCd>\tString\t등록자상위기관코드\t</rgtrUpInstCd>\n",
    "<rgtrUpInstCdNm>\tString\t등록자상위기관코드명\t</rgtrUpInstCdNm>\n",
    "<rgtrHghrkInstCd>\tString\t등록자최상위기관코드\t</rgtrHghrkInstCd>\n",
    "<rgtrHghrkInstCdNm>\tString\t등록자최상위기관코드명\t</rgtrHghrkInstCdNm>\n",
    "<zipCd>\tString\t정책거주지역코드\t</zipCd>\n",
    "<plcyMajorCd>\tString\t정책전공요건코드\t</plcyMajorCd>\n",
    "<jobCd>\tString\t정책취업요건코드\t</jobCd>\n",
    "<schoolCd>\tString\t정책학력요건코드\t</schoolCd>\n",
    "<aplyYmd>\tString\t신청기간\t</aplyYmd>\n",
    "<frstRegDt>\tString\t최초등록일시\t</frstRegDt>\n",
    "<lastMdfcnDt>\tString\t최종수정일시\t</lastMdfcnDt>\n",
    "<sBizCd>\tString\t정책특화요건코드\t</sBizCd>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac002bd5-ebeb-4f73-a39b-a705c8fd001d",
   "metadata": {
    "tags": []
   },
   "source": [
    "이 목록들을 보며 또 다른 고민이 든다.\n",
    "이 선별을 내가 직접 하는 것이 맞을까?\n",
    "어느 정보가 어떻게 필요할 줄 알고?\n",
    "또는 벡터 상에서 어떤 관계를 가질 줄 알고?\n",
    "머신러닝에서 딥러닝으로 전환되며, feature extracting 없이 말 그대로 거대한 양의 데이터를 떄려넣고 나온 결과물이 지금의 성능이 아닌가?\n",
    "오히려 이런 방법이 성능을 저하시킬 수 있지 않을까? 하는 고민.\n",
    "\n",
    "좀 더 생각해보니, 근본적으로 틀렸음을 알 수 있었다.\n",
    "학습과 활용의 영역. 이는 다르다는 것을.\n",
    "rag는 모델의 학습 영역이 아니다. 이를 활용하기 위한 방안이고, 따라서 이미 학습을 잘 한 모델에게 가장 정제된 데이터를 넘겨야 좋은 답변을 얻을 수 있다. garbage in garbage out. 이 원칙을 잊고 있었다.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "445ef3be-a8a1-43b1-95c3-810d6b5fb0a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "RAG 라는 것은 결과적으론 입력의 증강이다. R이 가져온 벡터들은 증강으로써 사용된다. 저장된 벡터들이 개판이라면 GIGO를 피할 수 없을 것이다.\n",
    "\n",
    "따라서 필요한 것들을 선별하고 재조립 하는 과정은 반드시 필요하다.\n",
    "\n",
    "\n",
    "---- 이런 생각들은 어떻게 정리?\n",
    "1. 코드는 깔끔히 유지\n",
    "2. 백로그 << 고민들에 대해 어떻게 했는지 글로 적어둔 것.. 형태는 여러가지.. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e18805-13f7-4a27-8b6f-3a1c400ee9d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "조금만 더 생각해보자.\n",
    "메타데이터의 역할이 무엇인가?\n",
    "=> 컨텐츠에 대한 부가적인 정보를 제공함으로써 정확도와 이해도를 높이는 것.\n",
    "\n",
    "그럼 어떤 것들이 메타데이터로 들어가야할까.. 생각해보자..\n",
    "\n",
    "\n",
    "일단 모든 출력 결과를 분석해보자\n",
    "정책 번호 : 사용자가 정책번호로도 검색이 가능하게 됨. 또는 질문 응대 실패 확률이 높을 때? 정책 이름과 번호를 이용한 검증? 같은 것이 가능하지 않을까\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9928fd8d-8700-416d-9906-6dc149ed2334",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. page_content 구성 (제안)\n",
    "page_content는 사용자가 자연어로 질문할 만한 내용을 모두 담고 있는 '본문' 역할을 해야 합니다. 정책의 설명, 내용, 자격, 방법 등 서술형 정보를 조합하는 것이 가장 이상적입니다.\n",
    "\n",
    "포함할 필드 추천:\n",
    "\n",
    "plcyNm (정책명)\n",
    "\n",
    "plcyExplnCn (정책설명)\n",
    "\n",
    "plcySprtCn (정책지원내용)\n",
    "\n",
    "addAplyQlfcCndCn (신청자격 조건)\n",
    "\n",
    "ptcpPrpTrgtCn (참여 제외 대상)\n",
    "\n",
    "plcyAplyMthdCn (신청 방법)\n",
    "\n",
    "srngMthdCn (심사 방법)\n",
    "\n",
    "sbmsnDcmntCn (제출 서류)\n",
    "\n",
    "이 필드들을 조합하면 \"어떤 혜택이 있고, 누가 신청할 수 있으며, 어떻게 신청하고, 어떤 서류가 필요한지\" 등의 질문에 효과적으로 답할 수 있는 텍스트가 만들어집니다.\n",
    "\n",
    "## 2. metadata 구성 (제안)\n",
    "metadata에는 각 텍스트 조각의 출처를 명확히 하고, 나중에 데이터를 필터링하는 데 사용할 정형 데이터를 넣습니다. ID, 이름, 날짜, URL, 분류 카테고리 등이 해당됩니다.\n",
    "\n",
    "포함할 필드 추천:\n",
    "\n",
    "기본 식별 정보: plcyNo (정책번호), plcyNm (정책명)\n",
    "\n",
    "기관 정보: sprvsnInstCdNm (주관기관명), operInstCdNm (운영기관명)\n",
    "\n",
    "earnMinAmt (소득최소금액) \n",
    "earnMaxAmt (소득최대금액)\n",
    "\n",
    "기간/일자 정보: aplyYmd (신청기간), bizPrdBgngYmd (사업 시작일), bizPrdEndYmd (사업 종료일), lastMdfcnDt (최종수정일)\n",
    "\n",
    "링크 정보: aplyUrlAddr (신청 URL), refUrlAddr1 (참고 URL 1)\n",
    "\n",
    "분류 정보: lclsfNm (대분류), mclsfNm (중분류), plcyKywdNm (키워드)\n",
    "\n",
    "핵심 조건: sprtTrgtMinAge (최소연령), sprtTrgtMaxAge (최대연령)\n",
    "\n",
    "\n",
    "구간 정보는 구간의 시작과 구간의 끝으로 분리할 것.\n",
    "\n",
    "구간 정보는 정확한 필터링을 위해 분리가 권장된다. 그래야 날짜로 인식하고 수학적 비교가 가능하거든. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6151cb3-ace5-4f5c-bcf1-ea402ed3cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def create_documents_from_csv(csv_file_path: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    CSV 파일에서 정책 정보를 읽어와\n",
    "    LangChain의 Document 객체 리스트로 변환합니다.\n",
    "\n",
    "    - 각 row는 하나의 정책 데이터를 나타냅니다.\n",
    "    - 서술형 정보는 page_content로 조합합니다.\n",
    "    - 정형 정보는 metadata로 저장합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    try:\n",
    "        # UTF-8 인코딩으로 CSV 파일을 엽니다.\n",
    "        with open(csv_file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "            # 각 row를 딕셔너리 형태로 읽어옵니다.\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            \n",
    "            for row in reader:\n",
    "                # 1. page_content 구성: 검색의 대상이 될 자연어 텍스트\n",
    "                page_content = f\"\"\"\n",
    "정책명: {row.get('plcyNm', '정보 없음')}\n",
    "정책 설명: {row.get('plcyExplnCn', '정보 없음')}\n",
    "지원 내용: {row.get('plcySprtCn', '정보 없음')}\n",
    "신청 자격: {row.get('addAplyQlfcCndCn', '정보 없음')}\n",
    "소득 조건: {row.get('earnEtcCn', '정보 없음')}\n",
    "참여 제외 대상: {row.get('ptcpPrpTrgtCn', '정보 없음')}\n",
    "신청 방법: {row.get('plcyAplyMthdCn', '정보 없음')}\n",
    "심사 방법: {row.get('srngMthdCn', '정보 없음')}\n",
    "제출 서류: {row.get('sbmsnDcmntCn', '정보 없음')}\n",
    "\"\"\"\n",
    "\n",
    "                # 2. metadata 구성: 필터링 및 출처 표시에 사용할 정형 데이터\n",
    "                metadata = {\n",
    "                    \"policy_id\": row.get('plcyNo'),\n",
    "                    \"policy_name\": row.get('plcyNm'),\n",
    "                    \"main_department\": row.get('sprvsnInstCdNm'),\n",
    "                    \"operating_department\": row.get('operInstCdNm'),\n",
    "                    \"business_period\": f\"{row.get('bizPrdBgngYmd')} ~ {row.get('bizPrdEndYmd')}\",\n",
    "                    \"last_updated\": row.get('lastMdfcnDt'),\n",
    "                    \"application_url\": row.get('aplyUrlAddr'),\n",
    "                    \"reference_url\": row.get('refUrlAddr1'),\n",
    "                    \"category_large\": row.get('lclsfNm'),\n",
    "                    \"category_medium\": row.get('mclsfNm'),\n",
    "                    \"keywords\": row.get('plcyKywdNm'),\n",
    "                    \"min_age\": row.get('sprtTrgtMinAge'),\n",
    "                    \"max_age\": row.get('sprtTrgtMaxAge'),\n",
    "                    \"income_min_amount\": row.get('earnMinAmt'),\n",
    "                    \"income_max_amount\": row.get('earnMaxAmt'),\n",
    "                }\n",
    "\n",
    "                # 신청 기간(aplyYmd)을 시작일과 종료일로 분리하는 로직\n",
    "                application_period_str = row.get('aplyYmd', '')\n",
    "                if ' ~ ' in application_period_str:\n",
    "                    try:\n",
    "                        start_date, end_date = application_period_str.split(' ~ ')\n",
    "                        metadata['application_start_date'] = start_date.strip()\n",
    "                        metadata['application_end_date'] = end_date.strip()\n",
    "                    except ValueError:\n",
    "                        metadata['application_period_raw'] = application_period_str\n",
    "                else:\n",
    "                    metadata['application_period_raw'] = application_period_str\n",
    "                \n",
    "                cleaned_metadata = {k: v for k, v in metadata.items() if v is not None and v != ''}\n",
    "                \n",
    "                documents.append(Document(page_content=page_content.strip(), metadata=cleaned_metadata))\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: '{csv_file_path}' 파일을 찾을 수 없습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"파일을 읽는 중 오류가 발생했습니다: {e}\")\n",
    "        \n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11048d2-0d79-4e10-994a-0fcc15a8fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 함수를 사용하여 Document 리스트 생성\n",
    "csv_file = \"./policy_data.csv\"\n",
    "processed_documents2 = create_documents_from_csv(csv_file)\n",
    "\n",
    "# 3. 결과 확인\n",
    "if processed_documents:\n",
    "    print(\"--- 첫 번째 Document 객체 ---\")\n",
    "    print(\"Page Content:\")\n",
    "    print(processed_documents[0].page_content)\n",
    "    print(\"\\nMetadata:\")\n",
    "    print(processed_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb03b30-101a-44db-b06e-c0d0b2c22643",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def create_documents_from_json(json_file_path: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    JSON 파일에서 정책 정보를 읽어와\n",
    "    LangChain의 Document 객체 리스트로 변환합니다.\n",
    "\n",
    "    - 함수 내부에서 파일을 열고 JSON을 파싱합니다.\n",
    "    - 서술형 정보는 page_content로 조합합니다.\n",
    "    - 정형 정보는 metadata로 저장합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    try:\n",
    "        # 파일을 열고 JSON 데이터를 파이썬 딕셔너리로 로드\n",
    "        with open(json_file_path, mode='r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # API 응답 구조에 따라 youthPolicyList에 접근\n",
    "        policy_list = data.get('result', {}).get('youthPolicyList', [])\n",
    "        \n",
    "        if not policy_list:\n",
    "            return documents\n",
    "\n",
    "        for policy in policy_list:\n",
    "            # 1. page_content 구성\n",
    "            page_content = f\"\"\"\n",
    "정책명: {policy.get('plcyNm', '정보 없음')}\n",
    "정책 설명: {policy.get('plcyExplnCn', '정보 없음')}\n",
    "지원 내용: {policy.get('plcySprtCn', '정보 없음')}\n",
    "신청 자격: {policy.get('addAplyQlfcCndCn', '정보 없음')}\n",
    "소득 조건: {policy.get('earnEtcCn', '정보 없음')}\n",
    "참여 제외 대상: {policy.get('ptcpPrpTrgtCn', '정보 없음')}\n",
    "신청 방법: {policy.get('plcyAplyMthdCn', '정보 없음')}\n",
    "심사 방법: {policy.get('srngMthdCn', '정보 없음')}\n",
    "제출 서류: {policy.get('sbmsnDcmntCn', '정보 없음')}\n",
    "\"\"\"\n",
    "\n",
    "            # 2. metadata 구성\n",
    "            metadata = {\n",
    "                \"policy_id\": policy.get('plcyNo'),\n",
    "                \"policy_name\": policy.get('plcyNm'),\n",
    "                \"main_department\": policy.get('sprvsnInstCdNm'),\n",
    "                \"operating_department\": policy.get('operInstCdNm'),\n",
    "                \"business_period\": f\"{policy.get('bizPrdBgngYmd')} ~ {policy.get('bizPrdEndYmd')}\",\n",
    "                \"last_updated\": policy.get('lastMdfcnDt'),\n",
    "                \"application_url\": policy.get('aplyUrlAddr'),\n",
    "                \"reference_url\": policy.get('refUrlAddr1'),\n",
    "                \"category_large\": policy.get('lclsfNm'),\n",
    "                \"category_medium\": policy.get('mclsfNm'),\n",
    "                \"keywords\": policy.get('plcyKywdNm'),\n",
    "                \"min_age\": policy.get('sprtTrgtMinAge'),\n",
    "                \"max_age\": policy.get('sprtTrgtMaxAge'),\n",
    "                \"income_min_amount\": policy.get('earnMinAmt'),\n",
    "                \"income_max_amount\": policy.get('earnMaxAmt'),\n",
    "            }\n",
    "\n",
    "            application_period_str = policy.get('aplyYmd', '')\n",
    "            if ' ~ ' in application_period_str:\n",
    "                try:\n",
    "                    start_date, end_date = application_period_str.split(' ~ ')\n",
    "                    metadata['application_start_date'] = start_date.strip()\n",
    "                    metadata['application_end_date'] = end_date.strip()\n",
    "                except ValueError:\n",
    "                    metadata['application_period_raw'] = application_period_str\n",
    "            else:\n",
    "                metadata['application_period_raw'] = application_period_str\n",
    "            \n",
    "            cleaned_metadata = {k: v for k, v in metadata.items() if v is not None and v != ''}\n",
    "            \n",
    "            documents.append(Document(page_content=page_content.strip(), metadata=cleaned_metadata))\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: '{json_file_path}' 파일을 찾을 수 없습니다.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"오류: '{json_file_path}' 파일이 올바른 JSON 형식이 아닙니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류가 발생했습니다: {e}\")\n",
    "        \n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297d0a8-93f3-4f5b-aee5-0fa4698a4f8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 사용 예시 ---\n",
    "\n",
    "\n",
    "# 2. 함수를 사용하여 Document 리스트 생성\n",
    "json_file = './policy_data.json'\n",
    "processed_documents = create_documents_from_json(json_file)\n",
    "\n",
    "# 3. 결과 확인\n",
    "if processed_documents:\n",
    "    print(\"--- 첫 번째 Document 객체 ---\")\n",
    "    print(\"Page Content:\")\n",
    "    print(processed_documents[0].page_content)\n",
    "    print(\"\\nMetadata:\")\n",
    "    print(processed_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846de052-28d6-4542-a73c-8e8e2918f2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in processed_documents:\n",
    "    print(\"--- 첫 번째 Document 객체 ---\")\n",
    "    print(\"Page Content:\")\n",
    "    print(i.page_content)\n",
    "    print(\"\\nMetadata:\")\n",
    "    print(i.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837856f6-908a-42b6-a55f-56200027601f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in processed_documents2:\n",
    "    print(\"--- 첫 번째 Document 객체 ---\")\n",
    "    print(\"Page Content:\")\n",
    "    print(i.page_content)\n",
    "    print(\"\\nMetadata:\")\n",
    "    print(i.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd1bcf-acf7-4974-9313-fe7699dfb223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청킹\n",
    "# 둘 다 해보지 머 .. 원래 AI의 사용은 보통 이런 식이니까\n",
    "# 1. RecursiveCharacterSplitter\n",
    "# 2. kss\n",
    "# 3. 문서 의미 기반 수동 분할 => 우리 데이터의 불규칙한 구조(assorted) 상 불가능.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d762055f-9384-44d4-8397-cfce54843b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. RecursiveCharacterSplitter\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. RecursiveCharacterTextSplitter 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len, # 글자 수 기준으로 나누겠다.\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# 2. 준비된 Document 리스트를 분할\n",
    "split_documents = text_splitter.split_documents(processed_documents2)\n",
    "\n",
    "\n",
    "# --- 결과 확인 (실제 실행 시 주석 해제) ---\n",
    "print(f\"원본 Document 수: {len(processed_documents2)}\")\n",
    "print(f\"분할된 Chunk 수: {len(split_documents)}\")\n",
    "\n",
    "# if split_documents:\n",
    "#     print(\"\\n--- 첫 번째 분할된 Chunk ---\")\n",
    "#     print(\"내용:\")\n",
    "#     print(split_documents[0].page_content)\n",
    "#     print(\"\\n메타데이터:\")\n",
    "#     print(split_documents[0].metadata)\n",
    "for i in processed_documents2[:10]:\n",
    "    print(\"내용:\")\n",
    "    print(i.page_content)\n",
    "    print(\"\\n메타데이터:\")\n",
    "    print(i.metadata)\n",
    "    print('--------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97921705-ef1b-4394-bc1b-87d77da3f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. kss 청킹\n",
    "\n",
    "import kss\n",
    "\n",
    "\n",
    "def split_docs_with_kss(documents: list[Document], chunk_size: int = 500) -> list[Document]:\n",
    "    \"\"\"\n",
    "    kss를 사용해 문서를 문장 단위로 분할하고,\n",
    "    정해진 chunk_size에 맞게 문장들을 다시 그룹화합니다.\n",
    "    \"\"\"\n",
    "    final_chunks = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # 1. kss로 전체 page_content를 문장 리스트로 분리\n",
    "        sentences = kss.split_sentences(doc.page_content)\n",
    "        \n",
    "        current_chunk_content = \"\"\n",
    "        # 2. 문장들을 순회하며 chunk_size에 가깝게 그룹으로 묶기\n",
    "        for sentence in sentences:\n",
    "            # 현재 문장을 추가하면 chunk_size를 초과하는지 확인\n",
    "            if len(current_chunk_content) + len(sentence) > chunk_size and current_chunk_content:\n",
    "                # 초과한다면, 현재까지의 내용을 하나의 chunk로 만듦\n",
    "                final_chunks.append(\n",
    "                    Document(page_content=current_chunk_content.strip(), metadata=doc.metadata)\n",
    "                )\n",
    "                # 새로운 chunk 시작\n",
    "                current_chunk_content = sentence\n",
    "            else:\n",
    "                # 초과하지 않으면, 현재 chunk에 문장 추가\n",
    "                current_chunk_content += \" \" + sentence\n",
    "\n",
    "        # 마지막에 남아있는 chunk를 리스트에 추가\n",
    "        if current_chunk_content:\n",
    "            final_chunks.append(\n",
    "                Document(page_content=current_chunk_content.strip(), metadata=doc.metadata)\n",
    "            )\n",
    "            \n",
    "    return final_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5227783-ec73-4a59-b386-6f8a47a2f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 사용 예시 ---\n",
    "kss_split_documents = split_docs_with_kss(processed_documents2, chunk_size=500)\n",
    "\n",
    "# --- 결과 확인 (실제 실행 시 주석 해제) ---\n",
    "print(f\"원본 Document 수: {len(processed_documents)}\")\n",
    "print(f\"분할된 Chunk 수 (kss): {len(kss_split_documents)}\")\n",
    "\n",
    "if kss_split_documents:\n",
    "    print(\"\\n--- 첫 번째 분할된 Chunk (kss) ---\")\n",
    "    print(kss_split_documents[0].page_content)\n",
    "    print(kss_split_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5d7b5-dd51-4083-9b2e-59e9ac85ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 하기\n",
    "# 프로토 구축이니깐.. 일단 그냥 openai api 사용하자.\n",
    "# 시간 나면 리더보드 보고 로컬로 해서 결과 비교도 해 보고~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc196a-c879-4820-8803-853c4123b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# 1. OpenAI 임베딩 모델 초기화\n",
    "# text-embedding-3-small은 비용과 성능 면에서 매우 효율적인 모델입니다.\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "# 2. 임베딩 및 FAISS 벡터 저장소 생성\n",
    "# from_documents 함수는 내부적으로 다음 두 가지 작업을 한번에 수행합니다.\n",
    "#  (1) split_documents의 각 chunk를 embeddings_model을 사용해 벡터로 변환\n",
    "#  (2) 변환된 벡터와 원본 chunk를 FAISS 데이터베이스에 저장\n",
    "db = FAISS.from_documents(split_documents, embeddings_model)\n",
    "\n",
    "\n",
    "# --- 테스트: 유사도 검색 ---\n",
    "# 생성된 벡터 저장소(db)가 잘 작동하는지 테스트합니다.\n",
    "query = \"미술 분야 청년을 위한 지원 정책 알려줘\"\n",
    "relevant_docs = db.similarity_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30313dec-ff93-49fd-98a3-ca512d99963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in relevant_docs:\n",
    "    print(i)\n",
    "    print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87dbf2-b3dc-43bd-b846-39ec77e80fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content 동적 생성으로 변경\n",
    "# 필드가 비었을 경우 그냥 가져가지 않도록.\n",
    "\n",
    "import csv\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def create_documents_from_csv(csv_file_path: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    CSV 파일에서 정책 정보를 읽어와\n",
    "    LangChain의 Document 객체 리스트로 변환합니다.\n",
    "\n",
    "    - 각 row는 하나의 정책 데이터를 나타냅니다.\n",
    "    - 서술형 정보는 page_content로 조합합니다.\n",
    "    - 정형 정보는 metadata로 저장합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    try:\n",
    "        with open(csv_file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            \n",
    "            for row in reader:\n",
    "                # --- 이 부분이 수정되었습니다 ---\n",
    "                # 1. page_content를 동적으로 구성하기 위한 리스트 생성\n",
    "                content_parts = []\n",
    "                \n",
    "                # content에 포함할 필드와 라벨을 정의\n",
    "                content_fields = [\n",
    "                    ('plcyNm', '정책명'),\n",
    "                    ('plcyExplnCn', '정책 설명'),\n",
    "                    ('plcySprtCn', '지원 내용'),\n",
    "                    ('addAplyQlfcCndCn', '신청 자격'),\n",
    "                    ('earnEtcCn', '소득 조건'),\n",
    "                    ('ptcpPrpTrgtCn', '참여 제외 대상'),\n",
    "                    ('plcyAplyMthdCn', '신청 방법'),\n",
    "                    ('srngMthdCn', '심사 방법'),\n",
    "                    ('sbmsnDcmntCn', '제출 서류')\n",
    "                ]\n",
    "                \n",
    "                # 각 필드에 대해 값이 존재하면 \"라벨: 값\" 형식으로 리스트에 추가\n",
    "                for field_key, field_label in content_fields:\n",
    "                    if row.get(field_key):\n",
    "                        content_parts.append(f\"{field_label}: {row[field_key]}\")\n",
    "                \n",
    "                # 리스트의 모든 요소를 줄바꿈으로 연결하여 최종 page_content 생성\n",
    "                page_content = \"\\n\".join(content_parts)\n",
    "                # ---------------------------------\n",
    "\n",
    "                # 2. metadata 구성 (이전과 동일)\n",
    "                metadata = {\n",
    "                    \"policy_id\": row.get('plcyNo'),\n",
    "                    \"policy_name\": row.get('plcyNm'),\n",
    "                    \"main_department\": row.get('sprvsnInstCdNm'),\n",
    "                    \"operating_department\": row.get('operInstCdNm'),\n",
    "                    \"business_period\": f\"{row.get('bizPrdBgngYmd')} ~ {row.get('bizPrdEndYmd')}\",\n",
    "                    \"last_updated\": row.get('lastMdfcnDt'),\n",
    "                    \"application_url\": row.get('aplyUrlAddr'),\n",
    "                    \"reference_url\": row.get('refUrlAddr1'),\n",
    "                    \"category_large\": row.get('lclsfNm'),\n",
    "                    \"category_medium\": row.get('mclsfNm'),\n",
    "                    \"keywords\": row.get('plcyKywdNm'),\n",
    "                    \"min_age\": row.get('sprtTrgtMinAge'),\n",
    "                    \"max_age\": row.get('sprtTrgtMaxAge'),\n",
    "                    \"income_min_amount\": row.get('earnMinAmt'),\n",
    "                    \"income_max_amount\": row.get('earnMaxAmt'),\n",
    "                }\n",
    "\n",
    "                # 신청 기간(aplyYmd) 분리 로직 (이전과 동일)\n",
    "                application_period_str = row.get('aplyYmd', '')\n",
    "                if ' ~ ' in application_period_str:\n",
    "                    try:\n",
    "                        start_date, end_date = application_period_str.split(' ~ ')\n",
    "                        metadata['application_start_date'] = start_date.strip()\n",
    "                        metadata['application_end_date'] = end_date.strip()\n",
    "                    except ValueError:\n",
    "                        metadata['application_period_raw'] = application_period_str\n",
    "                else:\n",
    "                    metadata['application_period_raw'] = application_period_str\n",
    "                \n",
    "                cleaned_metadata = {k: v for k, v in metadata.items() if v is not None and v != ''}\n",
    "                \n",
    "                documents.append(Document(page_content=page_content.strip(), metadata=cleaned_metadata))\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: '{csv_file_path}' 파일을 찾을 수 없습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"파일을 읽는 중 오류가 발생했습니다: {e}\")\n",
    "        \n",
    "    return documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_spike",
   "language": "python",
   "name": "langchain_spike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
